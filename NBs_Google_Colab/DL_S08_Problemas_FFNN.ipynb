{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL_S08_Problemas_FFNN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPfm49J93BTfCjLTXSsb6Di",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ssanchezgoe/curso_deep_learning_economia/blob/main/NBs_Google_Colab/DL_S08_Problemas_FFNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMTYh2DqhKFJ"
      },
      "source": [
        "<p><img alt=\"Colaboratory logo\" height=\"140px\" src=\"https://upload.wikimedia.org/wikipedia/commons/archive/f/fb/20161010213812%21Escudo-UdeA.svg\" align=\"left\" hspace=\"10px\" vspace=\"0px\"></p>\n",
        "\n",
        "<h1> Curso Deep Learning: Economía</h1>\n",
        "\n",
        "## S08: Arquitectura de Red FFNN: Problemas prácticos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTcDh7biuXEX"
      },
      "source": [
        "# Clasificación Binaria:\n",
        "\n",
        "**Objetivo:** Clasificación de reseñas de películas.\n",
        "\n",
        "**Input:** Reseñas\n",
        "\n",
        "**Output:** positiva o negativa.\n",
        "\n",
        "**Base de datos:** Se usará un dataset de IMDB (Internet Movie Databased) el cual consta de 50000 reseñas altamente polarizadas. Estas reseñas se dividen en un conjunto de 25000 reseñas para entrenamiento  y 25000 reseñas de evaluación, cada una de las cuales consta de un 50% de reseñas positivas y un 50% de reseñas negativas. \n",
        "\n",
        "El dataset de IMBD se encuentra Keras. Este dataset ha sido previamente procesado, en ddonde, las reseñas (secuencia de palabras) ha sido transformada en una secuencia de enteros, en donde cada entero corresponde a una palabra específica en un diccionario."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkHaibTQuP5L"
      },
      "source": [
        "from tensorflow import keras\n",
        "from keras.datasets import imdb\n",
        "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtDHkPNh08AY"
      },
      "source": [
        "train_data[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5jlry_6QuqFJ"
      },
      "source": [
        "A continuación, se realiza un tratamiento de los datos con el fin de convertirlos a vectores de `numpy` que puedan ser usados en una red neuronal. Para mayor información de este paso, consultar el libro del creador de `keras` [Deep learning with python](http://faculty.neu.edu.cn/yury/AAI/Textbook/Deep%20Learning%20with%20Python.pdf)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYuOT4O1ugOO"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def vectorize_sequences(sequences, dimension=10000): \n",
        "    results = np.zeros((len(sequences), dimension)) # Creates an all-zero matrix of shape (len(sequences), dimension)\n",
        "    for i, sequence in enumerate(sequences):\n",
        "        results[i, sequence] = 1.  # Sets specific indices of results[i] to 1s\n",
        "    return results\n",
        "\n",
        "x_train = vectorize_sequences(train_data) # Vectorized training data\n",
        "x_test = vectorize_sequences(test_data) # Vectorized training data\n",
        "\n",
        "y_train = np.asarray(train_labels).astype('float32') # Vectorized training labels. \n",
        "y_test = np.asarray(test_labels).astype('float32') # Vectorized test labels."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkqpMigU2Fbi"
      },
      "source": [
        "len(train_data[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6JSGoWn1j9A"
      },
      "source": [
        "x_train[1].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tm8Tq5CIwY1C"
      },
      "source": [
        "Definamos un modelo de dos capas ocultas, con funciones de activacióón **ReLU**, y una capa de salida con una función de activación **Sigmoide**, con el fin de abordar el problema de clasificación binario:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8M6rYWBRve03"
      },
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
        "model.add(layers.Dense(16, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBP06EgQ2gC6"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bscfzlH2flX"
      },
      "source": [
        "model.fit(x_train, y_train, epochs=4, batch_size=512,validation_data=(x_test,y_test))\n",
        "results = model.evaluate(x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W996ZjeJwuEo"
      },
      "source": [
        "results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0iPbKs0txGFe"
      },
      "source": [
        "# Predicción del modelo:\n",
        "model.predict(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hdeGGFQZ3JR_"
      },
      "source": [
        "y_preds=model.predict_classes(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmJBmx733W0L"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wKhMgCNA3a5A"
      },
      "source": [
        "confusion_matrix(y_test,y_preds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FW4aIk3u1BJP"
      },
      "source": [
        "# Clasificación Multiclase:\n",
        "\n",
        "**Objetivo:** Clasificación de un cable de noticias de un dataset de *Reuters*.\n",
        "\n",
        "**Input:** Noticias.\n",
        "\n",
        "**Output:** 46 topicos diferentes.\n",
        "\n",
        "**Base de datos:** Cada topido tiene al menos 10 ejemplos en el set de entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZAOSXbMeybJp"
      },
      "source": [
        "from keras.datasets import reuters\n",
        "(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words=10000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9DOYwoI1OtY"
      },
      "source": [
        "A continuación, se realiza un tratamiento de los datos con el fin de convertirlos a vectores de `numpy` que puedan ser usados en una red neuronal. Para mayor información de este paso, consultar el libro del creador de `keras` [Deep learning with python](http://faculty.neu.edu.cn/yury/AAI/Textbook/Deep%20Learning%20with%20Python.pdf)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TdAikHZa1Ilm"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def vectorize_sequences(sequences, dimension=10000):\n",
        "    results = np.zeros((len(sequences), dimension))\n",
        "    \n",
        "    for i, sequence in enumerate(sequences):\n",
        "        results[i, sequence] = 1.\n",
        "    return results\n",
        "\n",
        "x_train = vectorize_sequences(train_data)\n",
        "x_test = vectorize_sequences(test_data)\n",
        "\n",
        "def to_one_hot(labels, dimension=46): \n",
        "    results = np.zeros((len(labels), dimension))\n",
        "\n",
        "    for i, label in enumerate(labels):\n",
        "        results[i, label] = 1.\n",
        "        \n",
        "    return results\n",
        "\n",
        "one_hot_train_labels = to_one_hot(train_labels)\n",
        "one_hot_test_labels = to_one_hot(test_labels)\n",
        "\n",
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "one_hot_train_labels = to_categorical(train_labels)\n",
        "one_hot_test_labels = to_categorical(test_labels)\n",
        "\n",
        "x_val = x_train[:1000]\n",
        "partial_x_train = x_train[1000:]\n",
        "y_val = one_hot_train_labels[:1000]\n",
        "partial_y_train = one_hot_train_labels[1000:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bEx5IpI8ndX"
      },
      "source": [
        "train_labels[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6WukXfE8rNL"
      },
      "source": [
        "one_hot_train_labels[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2bCIqQV2swM"
      },
      "source": [
        "Creemos a continuación una red neuronal con dos capas ocultas (de 64 neuroranas cada una), con funciones de activación **ReLU**, y una capa de salida con una función de activación **softmax**, con 46 neuronas, una por cada tópico:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2X93NrX1cWM"
      },
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(46, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFJyfzVV8741"
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "loss='categorical_crossentropy',\n",
        "metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRLTgU9I9IN2"
      },
      "source": [
        "model.fit(partial_x_train, partial_y_train, epochs=9, batch_size=512, validation_data=(x_val, y_val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2TOSGUld9OAp"
      },
      "source": [
        "results = model.evaluate(x_test, one_hot_test_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-sDxFxYg3glK"
      },
      "source": [
        "Veamos los resultados de la evaluación del modelo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lhio9Ee10Xb"
      },
      "source": [
        "results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ks5ZRXK03jes"
      },
      "source": [
        "Y procesamos a entender los resultados de la prediccióón para una de las instancias del conjunto de evaluación:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UcHOlt0v2M3f"
      },
      "source": [
        "# predicción.\n",
        "predictions = model.predict(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h16itsE49XEZ"
      },
      "source": [
        "x_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0yt9-yBt9c9t"
      },
      "source": [
        "predictions[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ePLNbcPt33N0"
      },
      "source": [
        "Para la predicción de la instancia 0, se tiene que el vector de salida tiene la siguiente forma:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZA-6wj1r2bBw"
      },
      "source": [
        "predictions[0].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4HsY5RH4Edn"
      },
      "source": [
        "El vector tiene 46 entradas, que corresponden a las probabilidades de pertenencia a cada una de las 46 clases. La suma ade ellas debe ser uno:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbdc6ctF2hXj"
      },
      "source": [
        "np.sum(predictions[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1i1vJGN4QI7"
      },
      "source": [
        "La clase más probable a la cual pertenece esta instancia es la clase:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53Xu1GnR2kib"
      },
      "source": [
        "np.argmax(predictions[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "neMi3MIa9102"
      },
      "source": [
        "class_pred=model.predict_classes(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ln4JudK597D3"
      },
      "source": [
        "class_pred.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZKKamRJJ99V8"
      },
      "source": [
        "class_pred[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ml_USXwk4eGH"
      },
      "source": [
        "# Regresión: Predicción de los precios de una casa:\n",
        "\n",
        "Usaremos el dataset de los precios de casas en Bostón, para realizar la predicción.\n",
        "\n",
        "El objetivo es obtener a la salida de la red neuronal un valor numérico del precio predicho en función de las caracteristicas de la tabla.\n",
        "\n",
        "Definiremos un arquitectura de red con dos capas ocultas de 64 neuronas, usando una funcióón de activación **ReLu**, en cada una, y una capa de salida de una neurona, con una función de **activación lineal**:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhVvfpZz2mcI"
      },
      "source": [
        "from keras.datasets import boston_housing\n",
        "(train_data, train_targets), (test_data, test_targets) = boston_housing.load_data()\n",
        "\n",
        "# normalización de los datos\n",
        "mean = train_data.mean(axis=0)\n",
        "train_data -= mean\n",
        "std = train_data.std(axis=0)\n",
        "train_data /= std\n",
        "test_data -= mean\n",
        "test_data /= std\n",
        "\n",
        "#Función para la definición del modelo\n",
        "from keras import models\n",
        "from keras import layers\n",
        "def build_model(): \n",
        "  model = models.Sequential() \n",
        "  model.add(layers.Dense(64, activation='relu', input_shape=(train_data.shape[1],)))\n",
        "  model.add(layers.Dense(64, activation='relu'))\n",
        "  model.add(layers.Dense(1)) #Función de activación lineal\n",
        "  model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfEs3Pr3xvKp"
      },
      "source": [
        "train_data.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atBp6RMKxRHS"
      },
      "source": [
        "# Creación del modelo\n",
        "modelo = build_model()\n",
        "modelo.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAgxqXZCxSxI"
      },
      "source": [
        "modelo.fit(train_data, train_targets, epochs=500, batch_size=16,validation_data=(test_data,test_targets))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHHezKotxqRZ"
      },
      "source": [
        "test_mse_score, test_mae_score = modelo.evaluate(test_data, test_targets)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFhl7cTE5K3A"
      },
      "source": [
        "modelo.evaluate(train_data,train_targets)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evdyO4xM7Bax"
      },
      "source": [
        "modelo.evaluate(test_data,test_targets)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}