{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "s04.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ssanchezgoe/curso_deep_learning_economia/blob/main/nb_google_colab/s04_Pandas_II.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k113Yf1rMrs-"
      },
      "source": [
        "  <tr>\n",
        "     <th><p><img alt=\"Colaboratory logo\" height=\"120 px\" src=\"http://www.redttu.edu.co/es/wp-content/uploads/2016/01/iue.png\" align=\"left\" hspace=\"10px\" vspace=\"0px\"></p></th> \n",
        "     <th><h1>  Python: Pandas II </h1></th>\n",
        "  </tr>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GjgB7uVIMxvJ"
      },
      "source": [
        "<p><a name=\"contents\"></a></p>\n",
        "\n",
        "# Contenido Sesión 4\n",
        "\n",
        "- <a href=\"#misdat\">1. Procesamiento de datos nulos II</a><br>\n",
        " - <a href=\"#ignorarFila\">1.1  Ignorar fila de datos</a><br>\n",
        " - <a href=\"#valVec\">1.2 Llenado con valores vecinos</a><br>\n",
        " - <a href=\"#valSKL\">1.3 Llenado de datos usando sklearn</a><br>\n",
        " - <a href=\"#valMod\">1.4 Llenado con modelado</a><br>\n",
        "- <a href=\"#example\"> Ejemplo de preprocesado de datos</a><br>\n",
        "- <a href=\"#catvar\">2. Manipulación de variables categóricas</a><br>\n",
        " - <a href=\"#opevec\">2.1. Operaciones vectorizadas con `strings`</a><br>\n",
        " - <a href=\"#varord\">2.2. Variables ordinales: Codificación de enteros</a><br>\n",
        " - <a href=\"#varnom\">2.3. Variables nominales: Condificación one-hot (dummy variables)</a><br>\n",
        "- <a href=\"#groupby\">3. Groupby </a><br>\n",
        " - <a href=\"#trafil\">3.1. Funciones ` transform`  y ` filter` </a><br>\n",
        " - <a href=\"#cladiv\">3.2. Especificando la clave para la división del DataFrame  </a><br>\n",
        " - <a href=\"#tabdin\">3.3. Tablas dinámicas  </a><br>\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cv7-A1V-UXZk"
      },
      "source": [
        "<p><a name=\"misdat\"></a></p>\n",
        "\n",
        "# 1. Procesamiento de datos nulos II\n",
        "\n",
        "[[Contenidos]](#contents)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1DbRqOGOKz_"
      },
      "source": [
        "El dataset adult.csv fue extraído por Barry Becke de la base de datos de Censos de  1994. Contiene tanto variables numéricas como categóricas. La información de las variables y su contenido se presentan a continuación:\n",
        "\n",
        "age: continuo \\\\\n",
        "workclass: Private, Self-emp-not-inc, Self-emp-inc, Federal-gov, Local-gov, State-gov, Without-pay, Never-worked. \\\\\n",
        "fnlwgt: continuo. \\\\\n",
        "education: Bachelors, Some-college, 11th, HS-grad, Prof-school, Assoc-acdm, Assoc-voc, 9th, 7th-8th, 12th, Masters, 1st-4th, 10th, Doctorate, 5th-6th, Preschool. \\\\\n",
        "education-num: continuo. \\\\\n",
        "marital-status: Married-civ-spouse, Divorced, Never-married, Separated, Widowed, Married-spouse-absent, Married-AF-spouse. \\\\\n",
        "occupation: Tech-support, Craft-repair, Other-service, Sales, Exec-managerial, Prof-specialty, Handlers-cleaners, Machine-op-inspct, Adm-clerical, Farming-fishing, Transport-moving, Priv-house-serv, Protective-serv, Armed-Forces. \\\\\n",
        "relationship: Wife, Own-child, Husband, Not-in-family, Other-relative, Unmarried. \\\\\n",
        "race: White, Asian-Pac-Islander, Amer-Indian-Eskimo, Other, Black. \\\\\n",
        "sex: Female, Male. \\\\\n",
        "capital-gain: continuo. \\\\\n",
        "capital-loss: continuo. \\\\\n",
        "hours-per-week: continuo. \\\\\n",
        "native-country: United-States, Cambodia, England, Puerto-Rico, Canada, Germany, Outlying-US(Guam-USVI-etc), India, Japan, Greece, South, China, Cuba, Iran, Honduras, Philippines, Italy, Poland, Jamaica, Vietnam, Mexico, Portugal, Ireland, France, Dominican-Republic, Laos, Ecuador, Taiwan, Haiti, Columbia, Hungary, Guatemala, Nicaragua, Scotland, Thailand, Yugoslavia, El-Salvador, Trinadad&Tobago, Peru, Hong, Holand-Netherlands."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBd42EOZ73kb"
      },
      "source": [
        "import pandas as pd\n",
        "df=pd.read_csv('https://raw.githubusercontent.com/diplomado-bigdata-machinelearning-udea/Curso1/master/s04/adult.csv') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzJR--BvJIBB"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bDTdexkg8Mha"
      },
      "source": [
        "Encontrar el número de valores faltantes por columna"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XLO7RwAS758J"
      },
      "source": [
        "df.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgpbqN9Y8vmz"
      },
      "source": [
        "# Porcentaje de información faltante\n",
        "df.isnull().sum()/len(df)*100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLf7L32I9Btl"
      },
      "source": [
        "Podemos decir que hay cinco metodologías principales para hacer el tratamiento de los datos nulos:\n",
        "  \n",
        "1.  Reemplazar con un valor constante\n",
        "2. Reemplazar con un valor estadístico  (promedio, media, moda )\n",
        "3. Ignorar la fila de datos\n",
        "4.  Hacer un llenado hacia atrás (back-fill) o hacia adelante (forward-fill)\n",
        "5. Llenado basado en modelos\n",
        "\n",
        "Los dos primeros ya los cubrimos en la sesión anterior, así que enfoquemonos en los restantes.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ePjiNh8_jBc"
      },
      "source": [
        "<p><a name=\"ignorarFila\"></a></p>\n",
        "\n",
        "## 1.1 Ignorar fila de datos\n",
        "\n",
        "El comando `dropna()` permite eliminar las filas y/o columnas en las que hayan datos faltantes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Dn_mQbR_zLg"
      },
      "source": [
        "df_filtered=df.dropna()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vn7dg2X1AM6u"
      },
      "source": [
        "print('Número de filas iniciales', len(df))\n",
        "print('Número de filas después de filtrar', len(df_filtered))\n",
        "print('Porcentaje de filas eliminadas',(1-len(df_filtered)/len(df))*100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jb2PSxdBOyV"
      },
      "source": [
        "df_filtered.iloc[10:20,:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_P2_HhmCCLe"
      },
      "source": [
        "Note que los índices no cambian. Lo que realiza es la eliminación de la fila (por ejemplo la 14 no está), pero mantiene la indexación. Por tanto, estos no coinciden con el número total de filas. Para reasignar los índices se puede hacer uso del comando `reset_index()`  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adhecv_2CTPA"
      },
      "source": [
        "df_filtered.reset_index(drop=True,inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y62dvUuweo0z"
      },
      "source": [
        "df_filtered.tail()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ACDLQ-RBPz8"
      },
      "source": [
        "Se puede usar el argumento `subset` para seleccionar solo las columnas sobre las que se desea analizar si hay valores nulos para eliminar las filas "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vr9oMHoaAh1h"
      },
      "source": [
        "df.dropna(subset=['native-country'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QjdnLa4JDODa"
      },
      "source": [
        "<p><a name=\"valVec\"></a></p>\n",
        "\n",
        "## 1.2 Llenado con valores vecinos\n",
        "\n",
        "El comando `fillna()` tiene el argumento `method` que permite hacer un llenado hacia atrás ('bfill') o hacia adelante ('ffill').\n",
        "\n",
        "Tenga en cuenta que al usar ésta opción si el dato con el que se intenta hacer el llenado también es un NaN, éste permanece."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVtmiOQND4-g"
      },
      "source": [
        "df.iloc[25:30,:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30JsrTp7Dp-r"
      },
      "source": [
        "df.iloc[25:30,:].fillna(method='bfill')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmCwTnEhEqkW"
      },
      "source": [
        "df.iloc[25:30,:].fillna(method='ffill')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PdW_nqqpJ237"
      },
      "source": [
        "<p><a name=\"valSKL\"></a></p>\n",
        "\n",
        "## 1.3 Llenado de datos usando sklearn\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fMDq2jrnNAeY"
      },
      "source": [
        "Es posible también usar el metodo 'SimpleImputer' de la libreria sklearn para hacer llenado, éste nos permite definir cual estrategia usar para el llenado de los datos (media, mediana o moda)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JWrMndDKwOB"
      },
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "imp = SimpleImputer(strategy='most_frequent')\n",
        "X = df.iloc[25:30,:]\n",
        "trans = pd.DataFrame(imp.fit_transform(X))\n",
        "trans\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKXLnxZMS3VA"
      },
      "source": [
        "<p><a name=\"valMod\"></a></p>\n",
        "\n",
        "## 1.4 Llenado con modelado \n",
        "\n",
        "Una forma muy eficiente, pero más compleja de llenado de datos es convertir la columna a la que deseamos llenarle los datos faltantes y modelarla en función de las columnas sin datos faltantes.\n",
        "\n",
        "Dependiendo de la clase de dato podemos usar regresiones o clasificaciones. No profundizaremos en ésta estrategia pues aún no conocemos algoritmos de ML para ello."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tN2r1caMMvAQ"
      },
      "source": [
        "<p><a name=\"example\"></a></p>\n",
        "\n",
        "# Ejemplo de preprocesado de datos\n",
        "\n",
        "[[Contenidos]](#contents)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pRAYQDogZ0yr"
      },
      "source": [
        "Trataremos un ejemplo de una base de datos de una tabla de características de marcas de carros.\n",
        "\n",
        "De esta base de datos, pretendemos resolver el siguiente problema\n",
        "\n",
        "\n",
        "**Cual es la tasa de consumo en Litros por cada 100 km para un carro diesel?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P52CFxNvbF0t"
      },
      "source": [
        "## Importe de datos\n",
        "\n",
        "Los datos en crudo se pueden encontrar en la dirrección  https://archive.ics.uci.edu/ml/machine-learning-databases/autos/imports-85.data.\n",
        "\n",
        "**Importar panda y matplotlib.pyplot:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8-iWqavbaoE"
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69fQkpx1cGyI"
      },
      "source": [
        "### Lectura de los datos desde un url"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sZHvpPqbqzr"
      },
      "source": [
        "archivo = \"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DA0101EN/auto.csv\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hq-dV0N8cVKn"
      },
      "source": [
        "### Cabecera"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "llFJjCx-cMPb"
      },
      "source": [
        "headers = [\"symboling\",\"normalized-losses\",\"make\",\"fuel-type\",\"aspiration\", \"num-of-doors\",\"body-style\",\n",
        "         \"drive-wheels\",\"engine-location\",\"wheel-base\", \"length\",\"width\",\"height\",\"curb-weight\",\"engine-type\",\n",
        "         \"num-of-cylinders\", \"engine-size\",\"fuel-system\",\"bore\",\"stroke\",\"compression-ratio\",\"horsepower\",\n",
        "         \"peak-rpm\",\"city-mpg\",\"highway-mpg\",\"price\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fupH_mkickj0"
      },
      "source": [
        "### Carga de datos desde el url\n",
        "\n",
        "Para esto usamos el método `read_csv()`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVUmT3u8cZ9g"
      },
      "source": [
        "df = pd.read_csv(archivo, names = headers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ubmfMU_c3xx"
      },
      "source": [
        "### Inspección del archivo\n",
        "\n",
        "Recordemos que podemos usar el método head()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxstRO2GczBe"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3pd2EIDidHG9"
      },
      "source": [
        "Podemos observar que muchas de las entradas están etiquetadas con el símbolo `?`. Esto corresponde datos faltantes que pueden dificultar un análisis ulterior.\n",
        "\n",
        "Los pasos que debemos seguir a continuación son:\n",
        "\n",
        "\n",
        "\n",
        "1.   Identificar los valores faltantes\n",
        "2.   Tratar los valores faltantes.\n",
        "3.   Corregir el formato de los datos.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LBJ2AECseJ75"
      },
      "source": [
        "## Identificación de valores faltantes y tratamiento.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O0Nlya09eay-"
      },
      "source": [
        "### Conversión de `?` a `NaN`\n",
        "\n",
        "Quienes llenaron esta tabla, identificaron los valores faltantes como `?`.  Por razones de tiempo de computo y conveniencia, replazaremos estos signos de interrogación por `NaN`, para lo cual debemos importantar antes la librería numéricas de python numpy. \n",
        "\n",
        "Para realizar el reemplazo usaremos el método `replace()`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulNb4KK8diL6"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "df.replace(\"?\", np.nan, inplace = True) # No olvidarse de usar inplace.\n",
        "df.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdYJgpbhfvbG"
      },
      "source": [
        "### Identificación y conteo de valores faltantes:\n",
        "\n",
        "Apliquemos el método `isnull()` y utilicemos la función de agregación `sum()`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4CMjE7RgDyT"
      },
      "source": [
        "datos_faltantes = df.isnull().sum()\n",
        "datos_faltantes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79cLg6eLi8nZ"
      },
      "source": [
        "De acuerdo a la información anterior tenemos los siguientes datos faltantes.\n",
        "<ol>\n",
        "    <li>\"normalized-losses\": 41 </li>\n",
        "    <li>\"num-of-doors\": 2 </li>\n",
        "    <li>\"bore\": 4 </li>\n",
        "    <li>\"stroke\" : 4 </li>\n",
        "    <li>\"horsepower\": 2 </li>\n",
        "    <li>\"peak-rpm\": 2 </li>\n",
        "    <li>\"price\": 4 </li>\n",
        "</ol>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZA50X7gBjrtC"
      },
      "source": [
        "## Tratamiento de los datos faltantes\n",
        "\n",
        "<ol>\n",
        "    <li>Eliminar el dato entero<br>\n",
        "        a. Eliminar la fila entera<br>\n",
        "        b. Eliminar la columna entera\n",
        "    </li>\n",
        "    <li>Reemplazar el dato<br>\n",
        "        a. Reemplazar por la media<br>\n",
        "        b. Reemplazar por la moda<br>\n",
        "        c. Reemplazar basados en otra función\n",
        "    </li>\n",
        "</ol>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9zQg9S97kgOc"
      },
      "source": [
        "Solo debemos eliminar una columna si la mayoria de entradas son vacias. En nuestro caso, ninguna de las columnas cumplen con este criterio como para ser eliminadas. \n",
        "\n",
        "En este caso tenemos cierta libertad para aplicar diferences métodos de llenado de datos faltantes; no obstante, algunos métodos pueden resultar más adecuados que otros. Aplicaremos los siguientes métodos para cada columna:\n",
        "\n",
        "<b>Reemplazo por la media:</b>\n",
        "<ul>\n",
        "    <li>\"normalized-losses\": 41 datos faltantes</li>\n",
        "    <li>\"stroke\": 4 datos faltantes</li>\n",
        "    <li>\"bore\": 4 datos faltantes</li>\n",
        "    <li>\"horsepower\": 2 datos faltantes</li>\n",
        "    <li>\"peak-rpm\": 2 datos faltantes</li>\n",
        "</ul>\n",
        "\n",
        "<b>Replace por la moda:</b>\n",
        "<ul>\n",
        "    <li>\"num-of-doors\": 2 dátos faltantes que serán reemplazados por \"four\". \n",
        "        <ul>\n",
        "            <li>Razón: 84% de los sedan son 4 puertas. Dado que los carros cuatro puertas son los más frecuentes, la probabilidad de ocurrencia es mayor.</li>\n",
        "        </ul>\n",
        "    </li>\n",
        "</ul>\n",
        "\n",
        "<b>Eliminación de una fila entera:</b>\n",
        "<ul>\n",
        "    <li>\"price\": 4 datos faltantes\n",
        "        <ul>\n",
        "            <li>Razón: Como, eventualmente, el precio es algo que se puede predecir, ninguna entrada sin precio puede ser usada para una predicción; por ende, cualquier fila sin precio no será útil.</li>\n",
        "        </ul>\n",
        "    </li>\n",
        "</ul>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xphBQKHqnv2w"
      },
      "source": [
        "### Cálculo del valor medio"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64vtkwHkh3gK"
      },
      "source": [
        "avg_norm_loss = df[\"normalized-losses\"].astype(\"float\").mean(axis=0)\n",
        "print(\"Promedio de normalized-losses:\", avg_norm_loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXq7VyxFoDXl"
      },
      "source": [
        "Reemplazo de  \"NaN\" por el promedio en la columna \"normalized-losses\":"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhy_QQyzn8bK"
      },
      "source": [
        "df[\"normalized-losses\"].replace(np.nan, avg_norm_loss, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R0Mft1_RocXc"
      },
      "source": [
        "Calculo del valor medio para la columna 'bore':"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VVxT_EPuoQWE"
      },
      "source": [
        "avg_bore=df['bore'].astype('float').mean(axis=0)\n",
        "print(\"Average of bore:\", avg_bore)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xzEbhXenovYa"
      },
      "source": [
        "Reemplazo de `NaN` por  el valor medio"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_YxEzZToosP"
      },
      "source": [
        "df[\"bore\"].replace(np.nan, avg_bore, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gvJJsCOWo6Rb"
      },
      "source": [
        "**Ejercicio: De acuerdo a lo anterior reemplace los valores faltantes de la columna stroke por su valor medio**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AByRJeVLpROX"
      },
      "source": [
        "De doble click <b>aquí</b> para ver la solución:\n",
        "\n",
        "<!-- The answer is below:\n",
        "\n",
        "# Cálculo del valor medio:\n",
        "avg_stroke = df[\"stroke\"].astype(\"float\").mean(axis = 0)\n",
        "print(\"Average of stroke:\", avg_stroke)\n",
        "\n",
        "# Reemplazo de los valores faltantes por el valor medio\n",
        "df[\"stroke\"].replace(np.nan, avg_stroke, inplace = True)\n",
        "\n",
        "-->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTPfdz6dpzN2"
      },
      "source": [
        "Cálculo del valor medio de la columna 'horsepower' y reemplazo en los valores faltantes:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kKcx06ANpmK-"
      },
      "source": [
        "avg_horsepower = df['horsepower'].astype('float').mean(axis=0)\n",
        "print(\"Average horsepower:\", avg_horsepower)\n",
        "df['horsepower'].replace(np.nan, avg_horsepower, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xwag4aBUqM0v"
      },
      "source": [
        "Columna de 'peak-rpm':"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfNmpsbwqDM9"
      },
      "source": [
        "avg_peakrpm=df['peak-rpm'].astype('float').mean(axis=0)\n",
        "print(\"Average peak rpm:\", avg_peakrpm)\n",
        "df['peak-rpm'].replace(np.nan, avg_peakrpm, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ctZaadhqf1v"
      },
      "source": [
        "Para ver cuáles valores están presentes en una columna particular, podemos usar el método `value_counts()`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWfcc_O9qU4L"
      },
      "source": [
        "df['num-of-doors'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kd_yjHwTq3d2"
      },
      "source": [
        "Vemos que los carros de cuatro puertas son los más comunes. También podemos usar el método `.idxmax()` para calcular el tipo más común automaticamente:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z23QoIlUquW2"
      },
      "source": [
        "df['num-of-doors'].value_counts().idxmax()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLdSVmS7rc4f"
      },
      "source": [
        "Reemplazamos en la columna 'num-of-doors' los valores vacios por la moda:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Umm1y5crMkE"
      },
      "source": [
        "df[\"num-of-doors\"].replace(np.nan, \"four\", inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HlbZaR4FruN4"
      },
      "source": [
        "Finalmente, eliminemos todas las filas de carros sin precios:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1g3tolTVrsRD"
      },
      "source": [
        "# Eliminación de columnas sin precio mediante dropna\n",
        "df.dropna(subset=[\"price\"], axis=0, inplace=True)\n",
        "\n",
        "# Reinicio de los indices\n",
        "df.reset_index(drop=True, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2gJaqpRRsPSt"
      },
      "source": [
        "Apariencia de la tabla luego de preprocesarla"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jnshSMxsMBY"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMRKEg60srEb"
      },
      "source": [
        "## Corrección de datos\n",
        "\n",
        "<p>El último paso en el preprocesado de los datos consiste en revisar de que todos los datos estén en el formato adecuado(int, float, text u otro).</p>\n",
        "\n",
        "Podemos usar en Pandas\n",
        "<p><b>.dtypes()</b>  para ver el tipo</p>\n",
        "<p><b>.astype()</b> para cambiar el tipo</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZGBYLf8tS1m"
      },
      "source": [
        "### Lista de tipos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YgDt4jo5sTqT"
      },
      "source": [
        "df.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WckNYiM5tbzo"
      },
      "source": [
        "<p> Se puede observa que algunas columnas no tienen el tipo correcto.\n",
        "  \n",
        "  Las variables numéricas deben ser de tipo 'float' o 'int', y las variables con caracteres, como categorias, deben ser del tipo 'object'. Por ejemplo, 'bore' (diámetro del cilindro) y 'stroke' (ciclos/tiempos) son variables numéricas que describen el motor, esperamos entonces que sean de tipo 'float' o 'int'; no obstante, son de tipo 'object'. Debemos convertirlas a un tipo adecuado usantdo el método \"astype()\".</p> \n",
        "\n",
        "### Conversión al tipo adecuado:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdRYH7CytVtQ"
      },
      "source": [
        "df[[\"bore\", \"stroke\"]] = df[[\"bore\", \"stroke\"]].astype(\"float\")\n",
        "df[[\"normalized-losses\"]] = df[[\"normalized-losses\"]].astype(\"int\")\n",
        "df[[\"price\"]] = df[[\"price\"]].astype(\"float\")\n",
        "df[[\"peak-rpm\"]] = df[[\"peak-rpm\"]].astype(\"float\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9YbOvkHTvM5f"
      },
      "source": [
        "df.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSMyHNUOvjkl"
      },
      "source": [
        "Hemos obtenido, finalmente, un conjunto de datos correcto, sin datos faltantes y en un formato correcto."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19ObzndDv0W6"
      },
      "source": [
        "## Estandarización de datos\n",
        "\n",
        "<p>\n",
        "Los datos se recolectan, normalmente, de diferentes concesionarios, con diferentes formatos.\n",
        "(La estandarización de datos se refiere también a un tipo particular de normalización, en donde se extrae el promedio y se divíde por la desviación estándar.)\n",
        "</p>\n",
        "    \n",
        "<b>¿Qué es la estandarización?</b>\n",
        "<p>La estandarización es el proceso de transformar unos datos en un formato común que permita a los investigadores realizar comparaciones significativas.\n",
        "</p>\n",
        "\n",
        "<b>Ejemplo</b>\n",
        "<p>Transformar mpg (millas por galon) a L/100km (Litros por cada 100 km):</p>\n",
        "<p>En el conjunto de datos, \"city-mpg\" y \"highway-mpg\" están representadas en unidades de mpg. En europa, por ejemplo, el consumo se da en L/100km </p>\n",
        "<p>Debemos aplicar una <b>transformación de los datos</b> para pasar de  mpg a L/100km?</p>\n",
        "\n",
        "<p>La conversión es<p>\n",
        "L/100km = 235 / mpg\n",
        "<p>Podemos aplicar en Pandas operaciones matemáticas directamente para lograr este fin.</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0GX3gI0vPiY"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZOeJeb6ayFNw"
      },
      "source": [
        "# Conversión de mpg a L/100km\n",
        "df['city-L/100km'] = 235/df[\"city-mpg\"]\n",
        "\n",
        "# Visualización de la operación\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbDIQowkygjq"
      },
      "source": [
        "**Ejercicio:** De acuerdo con el procedimiento anterior, transforme mpg a L/100km en la columna de \"highway-mpg\", y cambie el nombre de la columna a highway-L/100km\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RuLNY0yJy7R8"
      },
      "source": [
        "De doble click <b>aquí</b> para ver la solución.\n",
        "\n",
        "<!-- \n",
        "\n",
        "# mpg a L/100km\n",
        "df[\"highway-mpg\"] = 235/df[\"highway-mpg\"]\n",
        "\n",
        "# renombre de \"highway-mpg\" a \"highway-L/100km\"\n",
        "df.rename(columns={'highway-mpg':'highway-L/100km'}, inplace=True)\n",
        "\n",
        "# visualización del conjunto de datos\n",
        "df.head()\n",
        "\n",
        "-->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2qADAWR0M7U"
      },
      "source": [
        "## Normalización de los datos\n",
        "\n",
        "<b>¿Por qué debemos aplica normalización?</b>\n",
        "<p>La normalización es el proceso de transforma valores de varias variables a un rango similar. Normalmente, la normalización incluye un escalado de las varialbres de tal forma que el promedio sea 0 y la varianza 1, o escalar las variables de tal forma que el rango esté definido entre 0 y 1.\n",
        "</p>\n",
        "\n",
        "<b>Ejemplo</b>\n",
        "<p>Supongamos que queremos rescalar las columnas \"length\", \"width\" and \"height\" </p>\n",
        "<p><b>Objetivo:</b> Normalizar las variables a un rango de 0 a 1.</p>\n",
        "<p><b>Métodología:</b> reemplazar el valor por (value original)/(valor máximo)</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fuzsbPIdzQP_"
      },
      "source": [
        "df['length'] = df['length']/df['length'].max()\n",
        "df['width'] = df['width']/df['width'].max()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zT-P8_Nr1qGN"
      },
      "source": [
        "**Ejercicio:** Normalice la columna \"heigh\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UeDBaRDn11fv"
      },
      "source": [
        "De doble click <b>aquí</b> para ver la solución.\n",
        "\n",
        "<!--\n",
        "\n",
        "df['height'] = df['height']/df['height'].max() \n",
        "# Mostrar las columnas normalizadas.\n",
        "df[[\"length\",\"width\",\"height\"]].head()\n",
        "\n",
        "-->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fr_ZlIMf2I7z"
      },
      "source": [
        "Podemos observar como el rango queda definido entre 0 y 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9x_604W2bFJ"
      },
      "source": [
        "## Bineado de los datos\n",
        "\n",
        "<b>Por qué binear?</b>\n",
        "<p>\n",
        "    Binear es el proceso que consiste en transformar una variable numérica continua en bines categoricos discretos, con el fin de realizar un analisis por grupos.\n",
        "</p>\n",
        "\n",
        "<b>Ejemplo: </b>\n",
        "<p>En nuestra base de datos, \"horsepower\" es una variable real que varia desde 48 a 288, tiene 57 valores únicos. Que pasaría si quisieramos discriminar entre diferentes precios dependiendo de si se trata de un \"horsepower\" alto, medio o bajo? Podemos reorganizarlos en bines para un analisis más simple? </p>\n",
        "\n",
        "<p>Usemos el método de pandas `cut` para partiro en tres bines: </p>\n",
        "\n",
        "<p>Primero convirtamos \"horsepower al formato correcto:\" </p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDKJhPaQ2DVd"
      },
      "source": [
        "df.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VrtXUtdf4CPi"
      },
      "source": [
        "df[\"horsepower\"]=df[\"horsepower\"].astype(int, copy=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7031soul4PZW"
      },
      "source": [
        "Realicemos un histograma de esta variable para ver como están distribuida:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zheBIHW4Gdp"
      },
      "source": [
        "import matplotlib as plt\n",
        "df.horsepower.hist()\n",
        "plt.pyplot.xlabel(\"horsepower\")\n",
        "plt.pyplot.ylabel(\"count\")\n",
        "plt.pyplot.title(\"horsepower bins\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfJobo974naN"
      },
      "source": [
        "<p> Para establecer 3 bines de ancho igual, usamos la función de numpy <code>linspace(start_value, end_value, numbers_generated)</code> .</p>\n",
        "<p>En estos casos tendríamos que</p>\n",
        " <p>start_value=min(df[\"horsepower\"]).</p>\n",
        "<p>end_value=max(df[\"horsepower\"]).</p>\n",
        "<p>Como queremos crea  3 bines del mismo ancho, usamos 4 como divisor /numbers_generated=4)</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_Ho83U04aLD"
      },
      "source": [
        "bins = np.linspace(min(df[\"horsepower\"]), max(df[\"horsepower\"]), 4)\n",
        "bins"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-i4zRGHo5h8D"
      },
      "source": [
        "Nombre de los grupos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTZzUTVN5gdr"
      },
      "source": [
        "group_names = ['Low', 'Medium', 'High']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "re2vT_8b5r6G"
      },
      "source": [
        "Aplicaciónde la función \"cut\"  para determinar que valor de \"df['horsepower']\" pertenece a qué categoría. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vY33i2-95lwo"
      },
      "source": [
        "df['horsepower-binned'] = pd.cut(df['horsepower'], bins, labels=group_names, include_lowest=True )\n",
        "df[['horsepower','horsepower-binned']].head(20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TO7OqfAW6Gr0"
      },
      "source": [
        "Veamos las cuentas por cada bin:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Upu0QVl46Fk3"
      },
      "source": [
        "df[\"horsepower-binned\"].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uVy6tIvf6OfI"
      },
      "source": [
        "Grafiquemos como están distribuidos por estas categorias la columna \"horsepower\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YshaU4bd6BME"
      },
      "source": [
        "import matplotlib as plt\n",
        "df[\"horsepower-binned\"].value_counts().plot(kind='bar')\n",
        "# set x/y labels and plot title\n",
        "plt.pyplot.xlabel(\"horsepower\")\n",
        "plt.pyplot.ylabel(\"count\")\n",
        "plt.pyplot.title(\"horsepower bins\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTaaxirT6xWm"
      },
      "source": [
        "## Visualización de los bins\n",
        "\n",
        "Normalmente,  un histograma se crea para ver la distribución de los bines que creamos arriba:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFxnqXUN6Z_w"
      },
      "source": [
        "import matplotlib as plt\n",
        "from matplotlib import pyplot\n",
        "\n",
        "a = (0,1,2)\n",
        "\n",
        "# draw historgram of attribute \"horsepower\" with bins = 3\n",
        "plt.pyplot.hist(df[\"horsepower\"], bins = 3)\n",
        "\n",
        "# set x/y labels and plot title\n",
        "plt.pyplot.xlabel(\"horsepower\")\n",
        "plt.pyplot.ylabel(\"count\")\n",
        "plt.pyplot.title(\"horsepower bins\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pWe5NlFP7Tbm"
      },
      "source": [
        "En la gráfica anterior se muestra el resultado del bineado para el atributo \"horsepower\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-exatoS27NQE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m1pOWQb2UXCr"
      },
      "source": [
        "<p><a name=\"catvar\"></a></p>\n",
        "\n",
        "# 2. Manipulación de variables categóricas\n",
        "\n",
        "[[Contenidos]](#contents)\n",
        "\n",
        "Las variables categóricas son aquellas que contienen etiquetas en vez de valores numéricos. Exiten variables categóricas ordinales y nominales, las primeras son aquellas que tienen algún tipo de jeraquización, como por ejemplo el nivel de escolaridad:*primaria, secundaria, universitaria*; las segunas son aquellas que no se pueden ordenar como profesión: *abogado, médico, ingeniero* . Según el problema que se desea resolver y el tipo de variables categóricas, estás deben tener un tratamiento diferente.\n",
        "\n",
        "Para ver más tipos de codificación ver: https://towardsdatascience.com/smarter-ways-to-encode-categorical-data-for-machine-learning-part-1-of-3-6dca2f71b159"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bukoINkZ6_UA"
      },
      "source": [
        "<p><a name=\"opevec\"></a></p>\n",
        "\n",
        "## 2.1. Operaciones vectorizadas con `strings`\n",
        "\n",
        "[[Contenidos]](#contents)\n",
        "\n",
        "Python ofrece una relativa facilidad en el manejo y manipulación de datos de tipo `str`. Pandas se basa en esto y proporciona un conjunto integral de operaciones vectorizadas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SrylJ0Yb8-nY"
      },
      "source": [
        "NumPy no proporciona un acceso tan simple. Por ejemplo, para escribir con mayúscula la primera letra de las entradas de un arreglo podemos escribir:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5T3xJPHZ8_-i"
      },
      "source": [
        "data = ['peter', 'Paul', 'MARY', 'gUIDO']       \n",
        "[s.capitalize() for s in data]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mGTMsOul9U3w"
      },
      "source": [
        "Quizás esto sea suficiente para trabajar con algunos datos, pero no funcionará si faltan valores:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vz0MKrHe9aTh"
      },
      "source": [
        "data = ['peter', 'Paul', None, 'MARY', 'gUIDO']       \n",
        "[s.capitalize() for s in data]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfH9iO689pTg"
      },
      "source": [
        "Pandas incluye opciones para abordar tanto el manejo de operaciones vectorizadas como el manejo correcto de los datos faltantes a través del atributo `str` de los objetos `series` e `index` de Pandas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeRPZFlf99sj"
      },
      "source": [
        "names = pd.Series(data)    \n",
        "names"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yr8qvJx2-g0J"
      },
      "source": [
        "Realicemos la operación anterior mediante el atributo `str` (note que se omiten los valores nulos)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "StnMGrp3-o2M"
      },
      "source": [
        "names.str.capitalize()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CizOcNZb_t9m"
      },
      "source": [
        "Casi todos los métodos incorporados de Python para el manejo de cadenas se reflejan en un método de vectorizado de cadenas de Pandas. Algunos de estos métodos son\n",
        "\n",
        "*   `len()`\n",
        "*   `lower()`\n",
        "* `upper()`\n",
        "*  `startswith()`\n",
        "* `contains()`\n",
        "*  `split()`\n",
        "* `get()`\n",
        "* `strip()`\n",
        "* `replace()`\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAr-h1InD9FY"
      },
      "source": [
        "monte = pd.Series([' Graham Chapman ', ' John Cleese', 'Terry Gilliam ', 'Eric Idle', 'Terry Jones', 'Michael Palin'])\n",
        "monte"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQOk1ozHEB7x"
      },
      "source": [
        "# entradas en letra minúscula (str)\n",
        "monte.str.lower() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzcGjBg4EhXl"
      },
      "source": [
        "# si la entrada contiene la letra T (bol)\n",
        "monte.str.contains('T')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqERLCeFFSXh"
      },
      "source": [
        "# separar por palabra (list)\n",
        "monte.str.split()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGmI0NgzF8LT"
      },
      "source": [
        "# obtener el apellido de cada entrada\n",
        "monte.str.split().str.get(-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHJpRpUgGZ1l"
      },
      "source": [
        "Para una guia completa visitar: https://pandas.pydata.org/pandas-docs/stable/user_guide/text.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQ0mqVhtpRfZ"
      },
      "source": [
        "<p><a name=\"varord\"></a></p>\n",
        "\n",
        "## 2.2. Variables ordinales: Codificación de enteros\n",
        "\n",
        "[[Contenidos]](#contents)\n",
        "\n",
        "La codificación entera (Integer Encoding) consiste en asignar un valor entero a cada uno de los valores ordenados, según correponda.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwnl_vZGjZj5"
      },
      "source": [
        "import pandas as pd\n",
        "df=pd.read_csv('https://raw.githubusercontent.com/diplomado-bigdata-machinelearning-udea/Curso1/master/s04/adult.csv') \n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XymzCVg7uSi4"
      },
      "source": [
        "Este tipo de implementación ya está hecha en el dataset para el caso del nivel educativo en las columnas education y education-num"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lx2QQN09t4bO"
      },
      "source": [
        "df[['education','education-num']].drop_duplicates().sort_values(by='education-num')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "irrjTZ1VvaNS"
      },
      "source": [
        "Con la función map es fácil de implementar en python. Por ejemplo para la columa class índiquemos con $1$ los $\\leq 50$ y con $2$ los $>50$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCfBmUVIuyrk"
      },
      "source": [
        "df['class'].unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5g_0h2Yxv1Lr"
      },
      "source": [
        "df['class-num']=df['class'].map({'<=50K':1, '>50K':2})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-xjjcoYwZ9W"
      },
      "source": [
        "df[['class-num','class']].head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8lUACCJSB2f"
      },
      "source": [
        "Podemos también convertir una columna a *category* y luego utilizar esos valores categóricos para la codificación entera. Por ejemplo, realicemos este proceso para la columna *workclass*. Convirtamos la columna al tipo *category*:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4-EuTsLSk7j"
      },
      "source": [
        "df[\"workclass\"] = df[\"workclass\"].astype(\"category\")\n",
        "df.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j2Mir3aDTVJH"
      },
      "source": [
        "Luego podemos asignar la variable codificada a una nueva columna utilizando `cat.codes`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EuQhmBdBTkgh"
      },
      "source": [
        "df[\"workclass_code\"] = df[\"workclass\"].cat.codes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NoR-N-sBTFCe"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7TA4qkUba5g"
      },
      "source": [
        "df[['workclass','workclass_code']].head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BnlYvBQsqJMz"
      },
      "source": [
        "<p><a name=\"varnom\"></a></p>\n",
        "\n",
        "## 2.3. Variables nominales: Condificación one-hot (dummy variables)\n",
        "\n",
        "[[Contenidos]](#contents)\n",
        "\n",
        "La codificación one-hot consiste asignar valores binarios $[1, 0]$ a las variables categóricas, en las que cada valor de la variable se convierte en un campo nuevo y se asigna el valor $[1, 0]$ si el evento contiene o no la variable según sea el caso.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zyZInwg3sp2m"
      },
      "source": [
        "df.sex.unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJYB8xwDyJW-"
      },
      "source": [
        "Pandas viene con el comando `pd.get_dummies()` que facilita el trabajo y realiza la codeificación one-hot de forma muy sencilla. Note que al implementar este comando, el campo `sex` se elimina y solo quedan las variables dummy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YH8iuO9fsu3s"
      },
      "source": [
        "pd.get_dummies(df.sex).head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQAvh1KgtVr4"
      },
      "source": [
        "Se puede implementar para el dataset completo y el comando `pd.get_dummies()` solo aplica sobre las variables categóricas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AfAuWvoctaVU"
      },
      "source": [
        "pd.get_dummies(df).head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IEJ2Kf_m0itM"
      },
      "source": [
        "Aplicar este tipo de codificación puede aumentar significativamente el número de variables. Esto depende de la cantidad de posibles valores que tengan las variables categóricas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKjFnock0Tvb"
      },
      "source": [
        "len(df.columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "orh6-g8Y0aQw"
      },
      "source": [
        "len(pd.get_dummies(df).columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-mwlBjOUWzk"
      },
      "source": [
        "<p><a name=\"groupby\"></a></p>\n",
        "\n",
        "# 3. Groupby\n",
        "\n",
        "[[Contenidos]](#contents)\n",
        "\n",
        "`Seaborn` es una libreria para hacer gráficos estadísticos en Python. Está construido sobre matplotlib y está estrechamente integrado con las estructuras de datos de pandas. Tiene incorporadas algunas bases de datos: \n",
        "\n",
        "https://github.com/mwaskom/seaborn-data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TLQD3OkJ3Qya"
      },
      "source": [
        "<p><a name=\"trafil\"></a></p>\n",
        "\n",
        "## 3.1. Funciones Transform y Filter\n",
        "\n",
        "[[Contenidos]](#contents)\n",
        "\n",
        "El dataset Planets, disponible a través del paquete Seaborn, da información sobre planetas descubiertos alrededor de otras estrellas. Se puede descargar via Seaborn de la siguiente manera. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j37XmbPU3UWu"
      },
      "source": [
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "planets = sns.load_dataset('planets')\n",
        "planets.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlsQALn_3f5t"
      },
      "source": [
        "Recordemos que Groupby nos ofrece las funciones `aggregate()` y `apply()`. \n",
        "\n",
        "`aggregate()` puede tomar una cadena, una función o una lista de estas, y calcular todos los agregados a la vez, mientras que `apply()` permite aplicar una función arbitraria a los resultados del agrupamiento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmFhJvcI3kEu"
      },
      "source": [
        "planets.groupby(\"method\").distance.aggregate([\"min\", \"max\", \"median\"])\n",
        "#planets.groupby(\"method\").distance.apply(np.min)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSMSyp_A3p9L"
      },
      "source": [
        "Si bien `aggregate()` debe devolver una versión reducida de los datos, `transform` puede devolver una versión transformada de los datos completos para que se recombinen. Para tal transformación, la salida tiene la misma forma que la entrada"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gL0Vaoot3q9T"
      },
      "source": [
        "df2 = planets.groupby('method')[[\"distance\"]].transform(\"median\").drop_duplicates()\n",
        "df2.reset_index(drop=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJKV9qqe314X"
      },
      "source": [
        "La operación `filter` permite eliminar datos en función de las propiedades del grupo. Note que esta rutina no filtra un marco de datos en su contenido. El filtro se aplica a las etiquetas del índice."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LtdStTBk320J"
      },
      "source": [
        "# agrupemos por método y filtremos los que operan a una distancia media mayor a 500\n",
        "\n",
        "def filter_func(x):\n",
        "    return x[\"distance\"].mean() > 500 #\n",
        "\n",
        "planets.groupby('method').filter(filter_func).method.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YbP9Uumo35fT"
      },
      "source": [
        "Ejemplo: Muestre el número de planetas descubiertos por método de detección y por década"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bl3Wh2Ka38Pc"
      },
      "source": [
        "decade = 10 * (planets['year'] // 10)    # serie que contiene las decadas\n",
        "decade = decade.astype(str) + 's'               \n",
        "planets.groupby(['method', decade])['number'].sum().unstack().fillna(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ux3x2PQy4XtZ"
      },
      "source": [
        "<p><a name=\"cladiv\"></a></p>\n",
        "\n",
        "## 3.2. Especificando la clave para la división del DataFrame \n",
        "\n",
        "[[Contenidos]](#contents)\n",
        "\n",
        "Los ejemplos presentados anteriormente expresan solo unas de las muchas opciones mediante las cuales se pueden definir los grupos. Veamos algunas otras opciones para la especificación de grupos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0J9eZlR4ZOB"
      },
      "source": [
        "# la clave puede ser cualquier serie o lista con una longitud que coincida con la del DataFrame\n",
        "\n",
        "rng = np.random.RandomState(0)        \n",
        "df = pd.DataFrame({'key': ['A', 'B', 'C', 'A', 'B', 'C'],'data1': range(1,7),'data2': rng.randint(0, 10, 6)}, \n",
        "                  columns = ['key', 'data1', 'data2']) \n",
        "print(df)\n",
        "\n",
        "# agrupar las filas 0 y 2 con índice \"a\"; las 1 y 3 con índice 1 ; las 4 y 5 con índice 10 y obtener la media\n",
        "L = [\"a\", 1, \"a\", 1, 10, 10]    \n",
        "df.groupby(L).mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97_8Tn5_4viv"
      },
      "source": [
        "Otro método es el de proporcionar un diccionario que asigne los valores de los índices a las claves de grupo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1LK12Gs4yj_"
      },
      "source": [
        "# asignar la columna \"key\" como índice\n",
        "df2 = df.set_index('key')   \n",
        "print(df2) \n",
        "\n",
        "# mapear los índices\n",
        "mapping = {'A': 'vowel', 'B': 'consonant', 'C': 'consonant'} \n",
        "print(df2.groupby(mapping).sum())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OwnGXibh43C3"
      },
      "source": [
        "Análogamente al mapeo, es posible pasar cualquier función de Python que ingrese el valor del índice y genere el grupo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rk31LKSN46MM"
      },
      "source": [
        "df2.groupby(str.lower).mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yoyO7SGs5Cjw"
      },
      "source": [
        "cualquiera de las opciones anteriores se pueden combinar para agrupar con índice múltiple"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8aDdhFu5D2H"
      },
      "source": [
        "mi = df2.groupby([str.lower, mapping]).mean()\n",
        "mi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qnJ3F9e65HIP"
      },
      "source": [
        "Se puede acceder a los diferentes niveles del índice múltiple mediante el argumento \"level\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0am5TxOR5LM7"
      },
      "source": [
        "mi.groupby(level=0).mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5dVCDkGz5Ok9"
      },
      "source": [
        "mi.groupby(level=1).mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PACI2ANP5TBE"
      },
      "source": [
        "<p><a name=\"tabdin\"></a></p>\n",
        "\n",
        "## 3.3. Tablas dinámicas\n",
        "\n",
        "[[Contenidos]](#contents)\n",
        "\n",
        "La tabla dinámica toma los datos de las columnas como entrada y las agrupa en una tabla que proporciona un resumen multidimensional de los datos. Es esencialmente una versión multidimensional de la agregación con GroupBy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZ2OkVi05T_G"
      },
      "source": [
        "En este caso importaremos el dataset \"titanic\" via seaborn, el cual contiene información sobre cada pasajero, incluyendo género, edad, clase, tarifa pagada y mucho más"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6mWjU6z5XPk"
      },
      "source": [
        "titanic = sns.load_dataset('titanic')\n",
        "titanic.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhzB9tzY5c_J"
      },
      "source": [
        "Para comenzar a aprender más sobre este dataset, podríamos comenzar por agrupar según el género, el estado de supervivencia o alguna combinación de estos. Veamos la tasa de supervivencia por género:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHjDDMgB5d1N"
      },
      "source": [
        "titanic.groupby('sex')[['survived']].mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQkT9N7J5jVk"
      },
      "source": [
        "Nos gustaría ir un paso más allá y ver la supervivencia por sexo y, por ejemplo, clase. Con GroupBy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9C3IzdB5kRt"
      },
      "source": [
        "titanic.groupby(['sex', 'class'])['survived'].aggregate('mean').unstack()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S7jAfkcO5qGb"
      },
      "source": [
        "Este GroupBy bidimensional es lo suficientemente común como para que Pandas incluya una rutina conveniente pivot_table que maneja este tipo de agregación multidimensional"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RjNcu-pB5rEH"
      },
      "source": [
        "titanic.pivot_table('survived', index='sex', columns='class')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQgp6UYa5zC5"
      },
      "source": [
        "Por defecto `pivot_table` aplica la función `mean()`. Para cambiar la función de agregación utilizamos el argumento `aggfunc`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXTU1mvs5zub"
      },
      "source": [
        "titanic.pivot_table(\"survived\", index='sex', columns='class', aggfunc=\"sum\")\n",
        "\n",
        "# agrupar por dos columnas y aplicar una función correspondiente a cada una\n",
        "\n",
        "#titanic.pivot_table(index='sex', columns='class', aggfunc={'survived':sum, 'fare':'mean'})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-ssf85L58rQ"
      },
      "source": [
        "la agrupación en tablas dinámicas se puede especificar con múltiples niveles. Podríamos estar interesados en ver la edad como una tercera dimensión. Seccionaremos la edad usando la función `pd.cut`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zEFImm1A5_kb"
      },
      "source": [
        "age = pd.cut(titanic['age'], [0, 18, 80])       \n",
        "titanic.pivot_table('survived', ['sex', age], 'class')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5o82eJk6DV-"
      },
      "source": [
        "Podemos aplicar esta misma estrategia para trabajar con las columnas. Agreguemos información sobre la tarifa pagada usando `pd.qcut` para calcular automáticamente los cuantiles"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vz8XVIFH6GC9"
      },
      "source": [
        "fare = pd.qcut(titanic['fare'], 2)       \n",
        "multi = titanic.pivot_table('survived', ['sex', age], [fare, 'class'])\n",
        "multi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLB7YLGc6K_U"
      },
      "source": [
        "El resultado es una agregación de cuatro dimensiones con índices jerárquicos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gz_PKT46Oh3"
      },
      "source": [
        "multi.mean(level=0)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZM5jUpg66YZZ"
      },
      "source": [
        "con la palabra clave `axis` podemos acceder a los niveles en las columnas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6THwfhF6ZEk"
      },
      "source": [
        "multi.mean(axis=1,level=\"class\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kALlzinI6eWL"
      },
      "source": [
        "A veces es útil calcular totales a lo largo de cada grupo. Esto se puede hacer a través de la palabra clave de `margin`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xxScQMS6fFo"
      },
      "source": [
        "titanic.pivot_table('survived', index='sex', columns='class', margins=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZwTjRvp1cVCx"
      },
      "source": [
        "##Taller\n",
        "\n",
        "A continuación cargaremos dos bases de datos con información referente a tarjetas de credito del mes 09 del 2017.\n",
        "\n",
        "El archivo ESTADO_201709.txt tal que:\n",
        "\n",
        "* ID:​ Nro. de identificación.\n",
        "* Franquicia:​ A, B, C.\n",
        "* Tipo Tarjeta:​ Representa el tipo de tarjeta.\n",
        "* Número Tarjeta:​ Indica el número de la TC.\n",
        "* Cupo Global:​ Indica el cupo de crédito que tiene la tarjeta.\n",
        "* Disponible: Indica del cupo global cuanto tiene a ese corte disponible para realizar compras o avances.\n",
        "* Fecha Emisión:​ Fecha en la que se compró la tarjeta.\n",
        "* Fecha Ult Aumento Cupo: Fecha en la que se realizó el último aumento de cupo. Cuando está en 0 significa que nunca se ha realizado un aumento de cupo.\n",
        "* Total Mes en Mora: Número de meses que ha estado en mora la TC (durante toda\n",
        "la vida de la tarjeta).\n",
        "*Altura de Mora: ​Indica la mora actual que tiene la TC. Viene en rango:\n",
        "  ○ 0 No está en mora,\n",
        "  ○ 30 está en mora hace menos de 30 días,\n",
        "  ○ 60 está en mora hace menos de 60 días.\n",
        "  ○ 90 está en mora hace menos de 90 días.\n",
        "*Código Vendedor:​ Indica el código del vendedor que emitió la TC.\n",
        "*Código Estado Tarjeta: Indica si la tarjeta está Activa o vigente (Codigo=0) y código = 1 (indica que la tarjeta está cancelada por el cliente).\n",
        "\n",
        "Y el archivo TRANSACCION_201709.txt, tal que:\n",
        "\n",
        "* ID:​ Nro de identificación.\n",
        "* Número Tarjeta:​ Indica el número de la TC que realizó la transacción.\n",
        "* Fecha de transacción​: Indica la fecha en que se realizó la transacción.\n",
        "* Codigo Transacción:\n",
        "  ○ AV : AVANCE\n",
        "  ○ AB: ABONO\n",
        "  ○ CN: COMPRA NACIONAL\n",
        "  ○ CI: COMPRA INTERNAL\n",
        "  ○ CM: CUOTA DE MANEJO.\n",
        "* Valor Transacción:​ Indica el valor de la transacción.\n",
        "* Numero Cuotas Diferidas: Indica el número de cuotas en el que el cliente desea pagar la compra.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXHoYXTkcXza"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "path = 'https://raw.githubusercontent.com/diplomado-bigdata-machinelearning-udea/Curso1/master/s04/'\n",
        "dfE = pd.read_csv(path+'ESTADO_201709.txt', delimiter=\"|\")\n",
        "dfT = pd.read_csv(path+'TRANSACCION_201709.txt', delimiter=\"|\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jlxe_nL_kvN5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CMfHq4E_lWDM"
      },
      "source": [
        "### Responda\n",
        "1. Imprima cada uno de los datasets para ver sus columnas\n",
        "2. Use el método merge para combinar los datasets  en el `NUMERO TARJETA' y haciendo la intersección.\n",
        "3. Busque los datos faltantes y determine una estrategia adecuada par su llenado.\n",
        "4. Convierta todas las fechas al fomato adecuado\n",
        "5. Genere un histograma de cada columna para ver su distribución\n",
        "6. Agrupe los datos por tipo de tarjeta y estado de la tarjeta. Hága un conteo ¿Existe alguna relación entre el tipo de tarjeta y la cancelación de la misma?\n",
        "7. Realice un bineo del total de meses en mora partiendolos en  tres categorías: 'baja mora','media mora','alta mora'. ¿Existe alguna relación entre la mora y la cancelación de la tarjeta?.\n",
        "8. Haga un gráfico de dispersión 'CODIGO VENDEDOR' vs 'CODIGO ESTADO TARJETA', ¿El vendedor de la tarjeta influencia las cancelaciones?.\n",
        "\n",
        "Recuerde hacer un analisis exploratorio de sus datos para familiarizarse con los datos antes de comenzar el análisis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9KZnPvoo60C"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}