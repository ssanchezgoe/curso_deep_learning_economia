{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "S06_Bases_Estadisticas.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMW+T1mwbzS5ij4sXws9eSU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ssanchezgoe/curso_deep_learning_economia/blob/main/Nb_Google_Colab/S06_Bases_Estadisticas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8XsvcYOlYfz"
      },
      "source": [
        "  <tr>\n",
        "     <th><p><img alt=\"Colaboratory logo\" height=\"80px\" src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/8/83/Sena_Colombia_logo.svg/1045px-Sena_Colombia_logo.svg.png\" align=\"left\" hspace=\"10px\" vspace=\"0px\"></p></th> \n",
        "    <th><p><img alt=\"Colaboratory logo\" height=\"80px\" src=\"https://www.isa.co/wp-content/uploads/2020/11/logo.png\" align=\"right\" hspace=\"10px\" vspace=\"0px\"></p></th>\n",
        "    <th><p><img alt=\"Colaboratory logo\" height=\"80px\" src=\"https://upload.wikimedia.org/wikipedia/commons/b/bf/EAFIT-2015.png\" align=\"left\" hspace=\"10px\" vspace=\"0px\"></p></th> \n",
        "     <th><h1>  Bases de Estadística Básica Aplicada </h1></th>\n",
        "  </tr>\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1uIkI-r9rTy9"
      },
      "source": [
        "## Regresión Lineal\n",
        "\n",
        "El problema de regresión lineal en una dimensión tiene como objetivo ajustar una variable numérica y continua,$y$, a una variable independiente $x$, por medio de un modelo lineal\n",
        "\n",
        "$$y = mx + b$$\n",
        "\n",
        "en donde los parámetros corresponden a:\n",
        "\n",
        "- $m$ pendiente de la recta.\n",
        "- $b$ intercepto con el eje $y$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqlxzP7_gV9W",
        "cellView": "form"
      },
      "source": [
        "#@title Librerías necesarias\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import linear_model\n",
        "from sklearn.linear_model import SGDRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from scipy.stats import pearsonr\n",
        "from numpy.random import randn\n",
        "from numpy.random import seed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tRH2dWagvkl8"
      },
      "source": [
        "x=10*np.random.rand(100)\n",
        "e=10*(np.random.rand(100)-0.5)\n",
        "y=3*x+5+e\n",
        "plt.scatter(x,y)\n",
        "plt.plot(np.arange(0,11),3*np.arange(0,11)+5,c='r')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENlcVgyrgsIU"
      },
      "source": [
        "La correlación entre ambos datos esta dada por:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ob42spuFgw4T"
      },
      "source": [
        "# Cálculo de la correlación de pearson.\n",
        "corr, _ = pearsonr(x, y)\n",
        "corr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-jgO21EwMBl"
      },
      "source": [
        "La línea recta sobre los puntos representa la tendencia del ajuste. En la figura se puede observar que esta línea no se ajusta a cada uno de los puntos; en su lugar, marca una tendencia promedio, por lo que se puede obtener un error en el ajuste a través de la distancia promedio de los puntos a la línea de tendencia:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03txq2GBwsBJ"
      },
      "source": [
        "plt.errorbar(x,y,yerr=np.c_[e,np.zeros_like(e)].T,fmt='none',c='m')\n",
        "plt.scatter(x,y)\n",
        "plt.plot(np.arange(0,11),3*np.arange(0,11)+5,c='r')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JxMwe-BExsLx"
      },
      "source": [
        "### Mínimos Cuadrados: Solución Analítica\n",
        "\n",
        "Al rededor de 1800 Carl Friederich Gauss y Adrien-Marie Legendre encontraron la forma de realizar un ajuste lineal, al minimizar la suma de los errores cuadráticos (MSE):\n",
        "\n",
        "$$\\text{MSE} = \\frac{1}{N}\\sum_{i=1}^N(\\hat{y}_i-y_i)^2$$\n",
        "\n",
        "en donde \n",
        "\n",
        "- $\\hat{y}_i$ corresponde al i-ésimo valor predicho por el modelo.\n",
        "- $y_i$ corresponde al i-ésimo valor del conjunto de datos de la variable objetivo.\n",
        "\n",
        "Se puede mostrar que los valores de la pendiente $m$ y el intercepto $c$ que minimizan la ecuación $y = mx + b$ están dados por\n",
        "\n",
        "$$m=\\frac{\\bar{xy}-\\bar{x}\\bar{y}}{\\bar{x^2}-\\bar{x}^2}$$\n",
        "\n",
        "$$b=\\bar{y}-m\\bar{x}$$\n",
        "\n",
        "en donde las cantidades con una barra corresponden a sus valores promedio.\n",
        "\n",
        "Los valores optimos serán entonces"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HwG7EsFW1qf8"
      },
      "source": [
        "N=len(x)\n",
        "m=(np.sum(x*y)-np.sum(x)*np.sum(y)/N)/(np.sum(x*x)-np.sum(x)**2/N)\n",
        "b=(np.sum(y)-m*np.sum(x))/N\n",
        "\n",
        "print('m',m)\n",
        "print('b',b)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAk6dcoLxoR6"
      },
      "source": [
        "plt.scatter(x,y)\n",
        "plt.plot(np.arange(0,10,10/100), m*np.arange(0,10,10/100)+b, c='r')\n",
        "plt.legend([\"Modelo\",\"Datos\"])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7fOhsO899Fi"
      },
      "source": [
        " print(f\"MSE: {mean_squared_error(y, m*x+b)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhItFQ7l2MUZ"
      },
      "source": [
        "El problema multidimensional de un ajuste lineal puede ser escrito como:\n",
        "\n",
        "$$y=a_0+a_1 x_1+a_2 x_2+...+a_m x_m=\\sum_{j=0}^m a_m x_m$$\n",
        "\n",
        "El cual puede ser resuelto analíticamente como:\n",
        "\n",
        "$$\\vec{a}=(a_0,a_1,...,a_m)=(X^T X)^{-1}X^T y$$\n",
        "\n",
        "Para lo que ser requiere de la inversión de la matriz $X^T X$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3ouVw343fvA"
      },
      "source": [
        "X=np.c_[np.ones_like(x),x]\n",
        "params = np.matmul(np.linalg.inv(np.matmul(X.T,X)),np.matmul(X.T,y))\n",
        "params"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZqVmzG0ozZDM"
      },
      "source": [
        "plt.scatter(x,y)\n",
        "plt.plot(np.arange(0,10,10/100), params[1]*np.arange(0,10,10/100)+params[0], c='r')\n",
        "plt.legend([\"Modelo\",\"Datos\"])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9e3HhLz0_AOU"
      },
      "source": [
        "print(f\"MSE: {mean_squared_error(y, params[1]*x+params[0])}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJCbyJVh3ip9"
      },
      "source": [
        "No obstante, si se poseen variabes características, la ecuación normal puede resultar computacionalmente lenta, debido a la inversión matricial que se reaquiere calcular. Para evitar esto, se hace uso de la técnica de descenso del gradiente."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DbwJiXUX2s6r"
      },
      "source": [
        "##  Solución en `sklearn`:\n",
        "\n",
        "La solución estándar en `sklearn` consiste en la siguientes líneas:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atNh0HdL3M61"
      },
      "source": [
        "lr = linear_model.LinearRegression()\n",
        "lr.fit(x.reshape(-1,1),y)\n",
        "print(f\"{lr.intercept_, lr.coef_[0]}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-UnqK3b1nn0"
      },
      "source": [
        "plt.scatter(x,y)\n",
        "plt.plot(np.arange(0,10,10/100), lr.coef_[0]*np.arange(0,10,10/100)+lr.intercept_, c='r')\n",
        "plt.legend([\"Modelo\",\"Datos\"])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IaIKxqVH_kZq"
      },
      "source": [
        "print(f\"MSE: {mean_squared_error(y, lr.coef_[0]*x+lr.intercept_)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LqT4lnO9Jqen"
      },
      "source": [
        "Si usamos decenso de gradiente, usamos el objeto de `sklearn` `SGDRegresor`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hsUibl2FM-K"
      },
      "source": [
        "model = SGDRegressor(max_iter=1000, tol=0.001, eta0=0.1)\n",
        "model.fit(x.reshape(-1,1),y)\n",
        "print(f\"{model.intercept_, model.coef_[0]}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MoZzYmT3EZx"
      },
      "source": [
        "plt.scatter(x,y)\n",
        "plt.plot(np.arange(0,10,10/100), model.coef_[0]*np.arange(0,10,10/100)+model.intercept_, c='r')\n",
        "plt.legend([\"Modelo\",\"Datos\"])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WVsi6Nsb_6Z_"
      },
      "source": [
        "print(f\"MSE: {mean_squared_error(y, model.coef_[0]*x+model.intercept_)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFmphkc08s5w"
      },
      "source": [
        "## Solución en `keras`:\n",
        "\n",
        "En `keras`, para implementar una regresión lineal, se programa una sola capa sin función de activación:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wG4zhTWd4uu0"
      },
      "source": [
        "from tensorflow import keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-s_W1MG6Sun"
      },
      "source": [
        "keras.backend.clear_session()\n",
        "model = keras.Sequential()\n",
        "model.add(keras.layers.Dense(1, input_shape=(1,)))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DeVUUAk6c-1"
      },
      "source": [
        "model.compile(keras.optimizers.Adam(learning_rate=0.9), 'mean_squared_error')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seL-lZ5r7bUC"
      },
      "source": [
        "model.fit(x,y,epochs=30)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJj6cBbp7tVJ"
      },
      "source": [
        "m,b = model.get_weights()\n",
        "print(f\"{b[0],m[0][0]}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AwSnRFAa3elS"
      },
      "source": [
        "plt.scatter(x,y)\n",
        "plt.plot(np.arange(0,10,10/100), m[0][0]*np.arange(0,10,10/100)+b[0], c='r')\n",
        "plt.legend([\"Modelo\",\"Datos\"])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gz3jUFS4AE9w"
      },
      "source": [
        "print(f\"MSE: {mean_squared_error(y, m[0][0]*x+b[0])}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJsVv7vl3tLS"
      },
      "source": [
        "## Ejercicios\n",
        "\n",
        "Para el siguiente conjunto de puntos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "A0R4mdnf4Elb"
      },
      "source": [
        "#@title Conjunto de datos xE, yE\n",
        "from sklearn.datasets import make_regression\n",
        "\n",
        "xE,yE = make_regression(n_samples=200, n_features=1, noise=3)\n",
        "plt.scatter(xE,yE)\n",
        "plt.xlabel(\"xE\")\n",
        "plt.ylabel(\"yE\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUoBDRUI5LY8"
      },
      "source": [
        "realice los ejercicios enumerados a continuación."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2JMKB-FD57Pj"
      },
      "source": [
        "### Ejercicio 1:\n",
        "\n",
        "Para este ejercicio: \n",
        "1. Realice un ajuste lineal, implementando una función para el método de mínimos cuadrados\n",
        "2. Desarrolle una función que grafique el conjunto de datos y el modelo. \n",
        "3. Calcule el valor del error cuadrático medio."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dcmijtUw7GPC"
      },
      "source": [
        "### Ejercicio 2:\n",
        "\n",
        "Para este ejercicio:\n",
        "1. Realice un ajuste lineal siguiendo el método estándard de `skelearn`. \n",
        "2. Haga uso de la función implementada en el ejercicio 1 para visualizar los datos y el modelo.\n",
        "3. Calcule el valor del error cuadrático medio."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fl3OjnAC7d1V"
      },
      "source": [
        "### Ejercicio 3:\n",
        "\n",
        "Para este ejercicio:\n",
        "1. Realice un ajuste lineal siguiendo el método de descenso de gradiente estocástico implementado en `sklearn`, usando varios modelos en donde evalue varios valores de los parámetros vistos:\n",
        "\n",
        "  - `max_iter`\n",
        "  - `tol`\n",
        "  - `eta0`\n",
        "\n",
        "2. Visualice los datos junto al modelo, en cada conjunto de parámetros analizado.\n",
        "3. Calcule el valor del error cuadrático medio."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CKOdyyQY8mNc"
      },
      "source": [
        "### Ejercicio 4:\n",
        "\n",
        "Para este ejercicio:\n",
        "1. Realice un ajuste lineal implementando el método de `keras`. \n",
        "2. Visualice el modelo junto a los datos.\n",
        "3. Calcule el valor del error cuadrático medio."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKWQKOSlpGHk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3O4ISooUlm_"
      },
      "source": [
        "<p><a name=\"redela\"></a></p>\n",
        "\n",
        "# 1. Redes elásticas\n",
        "\n",
        "[[Contenidos]](#contents)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNw4dr2v2tsV"
      },
      "source": [
        "Como vimos anteriormente, podemos generar penalizaciones a las regresiones lineales haciendo cambios en su metrica de error.\n",
        "\n",
        "Para la regresión Ridge se penaliza con: $\\alpha \\sum w_i^2$ (penalidad $L_2$), mientras que para Lasso se tiene que: \n",
        "$\\alpha \\sum |w_i|$ (penalidad $L_1$). Cada una de ellas tenía sus pro y sus contra. Pero es posible hacer una combinación de ambos metodos.\n",
        "\n",
        "A las regresiones que usan una combinación de ambas penalidades se les conoce como **ElasticNet** (Redes elásticas) y definimos su error como:\n",
        "$$\\sum (Y_i- \\hat Y_i)^2+\\alpha \\rho \\sum |w_i| + \\frac{\\alpha(1-\\rho)}{2}\\sum w_i^2. $$\n",
        "\n",
        "Note que cuando $ \\rho=1$ tenemos la regresión Lasso, y con $\\rho=0$ tendremos la de Ridge, por tanto en las redes elásticas $0\\leq \\rho\\leq1$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dU8NhFaQ-UHB"
      },
      "source": [
        "Hemos dado un paso más en la complejización del modelo ya que ahora debemos preocuparnos por el ajuste de 2 hiperparámetros para seleccionar el mejor modelo.\n",
        "\n",
        "Para usar las redes elásticas en sklearn debemos importar la función 'ElasticNet' del modulo de modelos lineales."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9KmzhnX-MOs"
      },
      "source": [
        "from sklearn.linear_model import ElasticNet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5gRbxEi_eZg"
      },
      "source": [
        "En la implementación de sklearn tenemos los hiperparámetros 'alpha' y 'l1_ratio' ($\\rho$ en nuestra ecuación), con ellos controlaremos el comportamiento del regresor.\n",
        "\n",
        "Tenga en cuenta que para valores de *l1_ratio* $\\leq0.01$ el algoritmo de sklearn no es estable si usamos el valor de $\\alpha$ por defecto y se hace necesario que nosotros mísmos ajustemos el valor. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMTIOIlLAnZ4"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "df=pd.read_csv('https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/ML0101ENv3/labs/FuelConsumptionCo2.csv')\n",
        "\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "X = df['ENGINESIZE'].values.reshape(-1,1)\n",
        "y = df['CO2EMISSIONS'].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7U7_NsiKA-L9"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import ElasticNet\n",
        "from sklearn import metrics\n",
        "\n",
        "#seleccionamos los datos de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=3)\n",
        "\n",
        "#entrenamos el modelo\n",
        "elastic = ElasticNet(alpha=0.01,l1_ratio=1,normalize=True)\n",
        "elastic.fit(X_train,y_train)\n",
        "y_pred = elastic.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFNqiFJxBuQg"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.scatter(X_test, y_test,  color='black',label=r'datos test')\n",
        "plt.scatter(X_train, y_train,  color='red',alpha=0.4,label=r'datos entrenamiento')\n",
        "plt.plot(X_test, y_pred, color='blue',label=r'predicción')\n",
        "plt.legend(loc='best')\n",
        "plt.xlabel(r'Engine size')\n",
        "plt.ylabel(r'Price')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZOD-5UQ_CCce"
      },
      "source": [
        "print('MAE: ', metrics.mean_absolute_error(y_test, y_pred))\n",
        "print('MSE: ', metrics.mean_squared_error(y_test, y_pred))\n",
        "print('RMSE: ', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
        "print('R2: ', elastic.score(X_test,y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HWJtcaWsGTYB"
      },
      "source": [
        "De nuevo, los hiperparámetros debemos seleccionarlos con una busqueda para determinar una buena combinación."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wz4BbkjgIGru"
      },
      "source": [
        "#### Ejercicio:\n",
        "\n",
        "1. En el dataset de autos (a1): elimine los datos faltantes, convierta las variables categoricas en variables dummies (a2), y separe el dataset en datos de entrenamiento y prueba.\n",
        "\n",
        "2. Use dos ciclos 'for' para recorrer $\\alpha$ en la lista [0.01,0.1,1,10,100,1000] y l1_ratio en [0.1,0.3,0.6,0.9,0.99,0.999], entrenando un modelo ElasticNet para las combinaciones de éstos y evaluandolo con RMSE. Guarde el valor de cada RMSE en un arreglo.\n",
        "\n",
        "3. Haga un mapa de calor (a3) con los valores de $\\alpha$ y l1_ratio del punto anterior y los valores de RMSE.\n",
        "\n",
        "\n",
        "a1. 'https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DA0101EN/automobileEDA.csv'\n",
        "\n",
        "a2. `pd.get_dummies()`\n",
        "\n",
        "a3. `sns.heatmap(Matriz, xticklabels, yticklabels, annot=True)`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3MLNkhf9TS9A"
      },
      "source": [
        "Hacer doble click **aquí** para ver la solución:\n",
        "\n",
        "<!-- Respuesta:\n",
        "\n",
        "\n",
        "#1\n",
        "#eliminamos datos nulos\n",
        "df.dropna(inplace=True)\n",
        "#creamos las variables dummies\n",
        "df_dummies = pd.get_dummies(df)\n",
        "#separamos el dataset\n",
        "X = df_dummies.drop('price',axis=1)\n",
        "y = df_dummies['price']\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3)\n",
        "\n",
        "#2\n",
        "#Creamos la lista de alphas, l1_ratios y el arreglo de RMESs\n",
        "alphas =  [0.01,0.1,1,10,100,1000] \n",
        "l1s = [0.1,0.3,0.6,0.9,0.99,0.999]\n",
        "RMSEs = []\n",
        "\n",
        "#Recorremos los valores en los arreglos\n",
        "for alpha in alphas:\n",
        "  for l1 in l1s:\n",
        "    elastic = ElasticNet(alpha=alpha,l1_ratio=l1,normalize=True)\n",
        "    elastic.fit(X_train,y_train)\n",
        "    y_pred = elastic.predict(X_test)\n",
        "    RMSE = np.sqrt(metrics.mean_squared_error(y_test, y_pred))\n",
        "    #el metodo append agrega un valor al arreglo  \n",
        "    RMSEs.append(RMSE)\n",
        "RMSEs = np.array(RMSEs)\n",
        "\n",
        "#3\n",
        "import seaborn as sns\n",
        "#pasamos de un arreglo a una matriz para usarlo en el mapa de calor\n",
        "RMSEs = RMSEs.reshape(len(alphas),len(l1s))\n",
        "sns.heatmap(RMSEs, xticklabels=alphas, yticklabels=l1s,annot=True )\n",
        "\n",
        "--->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzSujHsuUbq1"
      },
      "source": [
        "<p><a name=\"met\"></a></p>\n",
        "\n",
        "# 2. Métricas\n",
        "\n",
        "[[Contenidos]](#contents)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGFxtafDqn9z"
      },
      "source": [
        "En la sesión anterior estudiamos un modelo de regresión simple, por medio del cual se hace una predicción calculando una suma ponderada de las características de entrada, más una constante llamada término de sesgo (también llamado intercepto).\n",
        "\n",
        "$$y=w_0+w_1x_1+w_2x_2+...+w_nx_n$$\n",
        "\n",
        "Primero necesitamos de una medida de qué tan bien (o mal) el modelo se ajusta a los datos de entrenamiento. Esta medida de evaluación (función de costo) es el error calculado entre la recta generada $\\hat{y}$ (o el hiperplano) a los puntos reales. El entrenamiento del modelo será entonces encontrar los valores de $w_i$ que minimicen dicha función de costo. Entre las métricas más populares encontramos:\n",
        "\n",
        "* Error medio absoluto (MAE)\n",
        "\n",
        "$$MAE = \\frac{1}{m}\\sum_{i=1}^{m}|\\hat{y}_i -y_i|$$\n",
        "\n",
        "* Error cuadrático medio (MSE)\n",
        "\n",
        "$$MSE=\\frac{1}{m}\\sum_{i=1}^{m}\\left(\\hat{y}_i -y_i\\right)^2$$\n",
        "\n",
        "* Raíz del error cuadrático medio (RMSE)\n",
        "\n",
        "$$RMSE=\\sqrt{\\frac{1}{m}\\sum_{i=1}^{m}\\left(\\hat{y}({\\bf x})_i -y_i\\right)^2}$$\n",
        "\n",
        "Estas métricas las podemos obtener del módulo [metrics](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics) de sklearn. Apliquémoslas al modelo lineal simple estudiado en la sesión anterior:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uiX9gWqvrA4K"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "archivo = 'https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DA0101EN/automobileEDA.csv'\n",
        "df = pd.read_csv(archivo)\n",
        "\n",
        "#separemos nuestros datos en características y etiquetas\n",
        "X = df['engine-size'].values.reshape(-1,1)\n",
        "y = df['price'].values.reshape(-1,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DB4EG-D2rHPA"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn import metrics\n",
        "\n",
        "#seleccionamos los datos de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=3)\n",
        "\n",
        "#entrenamos el modelo\n",
        "linear  = LinearRegression(normalize=True)\n",
        "linear.fit(X_train,y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WeuSUl1r_un"
      },
      "source": [
        "Obtengamos ahora los datos predichos por el modelo y calculemos las métricas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqUwxeKutgLX"
      },
      "source": [
        "y_pred = linear.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHk4jH7isHvT"
      },
      "source": [
        "plt.scatter(X_test, y_test,  color='black',label=r'datos test')\n",
        "plt.scatter(X_train, y_train,  color='red',alpha=0.4,label=r'datos entrenamiento')\n",
        "plt.plot(X_test, y_pred, color='blue',label=r'predicción')\n",
        "plt.legend(loc='lower right')\n",
        "plt.xlabel(r'Engine size')\n",
        "plt.ylabel(r'Price')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tIeSDGDvrP4Q"
      },
      "source": [
        "print('MAE: ', metrics.mean_absolute_error(y_test, y_pred))\n",
        "print('MSE: ', metrics.mean_squared_error(y_test, y_pred))\n",
        "print('RMSE: ', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xwqtw87QrXvY"
      },
      "source": [
        "Y calculemos el coeficiente de correlación $R^2$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4U2cI0vrYoh"
      },
      "source": [
        "print('R2: ', metrics.r2_score(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0tpklp-3rcp-"
      },
      "source": [
        "Comprobemos además si los errores se distribuyen según una distribución normal, lo que nos da una prueba de la validez de nuestro modelo. El siguiente se conoce como un *histograma de residuos*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "olyl_xEzrdhQ"
      },
      "source": [
        "sns.distplot((y_test - y_pred), bins = 50)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mIzKAizKuQro"
      },
      "source": [
        "Una vez que hemos entrenado el modelo de regresión lineal las predicciones se obtienen rápidamente. La complejidad computacional es lineal con respecto a la cantidad de instancias y características sobre las que desea hacer predicciones. En otras palabras, hacer predicciones con el doble de instancias (o el doble de características) tomará aproximadamente el doble de tiempo de computo. Existen diferentes formas de entrenar un modelo de regresión lineal, más adecuado para casos en los que hay una gran cantidad de características o demasiadas instancias de entrenamiento para que quepan en memoria.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xSHqRFKkUhCJ"
      },
      "source": [
        "<p><a name=\"regpol\"></a></p>\n",
        "\n",
        "# 3. Regresión polinómica\n",
        "\n",
        "[[Contenidos]](#contents)\n",
        "\n",
        "**Regresión Polinómica**\n",
        "\n",
        "Hasta ahora nos hemos centrado en la creación de modelos lineales simples y multivariados en donde la relación entre la/las variable/variables predictora/predictoras y la variable blanco corrsponde a una relación lineal. \n",
        "\n",
        "No obstante, en algunas ocasiones las tendencias de los datos presentan un comportamiento curvo. En estos caso debemos buscar otro modelo para representar los datos, como es el método de **regresión polinómica**. Dentro de la regreción polinómica, tenemos varias tipos de regresiones dependiendo del grado del polinómio que usemos:\n",
        "\n",
        "* Cuadrática: Si el polinomio que usamos es grado dos.\n",
        "* Cúbica: Si el polinomio que usamos es grado tres.\n",
        "* Cuártica: Si el polinomio que usamos es grado cuatro.\n",
        "* etc\n",
        "\n",
        "Podemos llamar a todos estos casos regresiones polinómicas, ya que la relación entre la variable independiente $x$ y la variable dependiente  $y$ se modela mediante un polinomio de grado n en la variable $x$:\n",
        "\n",
        "\\begin{equation}\n",
        "\\hat{y}=w_0x^0+w_1x^1+w_2x^2\\cdots w_nx^x = \\sum_{i=0}^nw_ix^i\n",
        "\\end{equation}\n",
        "\n",
        "En donde los $w$'s representan los parámetros del ajuste o la regresión \n",
        "\n",
        "**¿Cómo podemos abordar una regresión polinómica?**\n",
        "\n",
        "Existe un \"truco\" que nos permite convertir una regresión polinómica en una regresión lineal múltiple. Si definimos:\n",
        "\n",
        "* $x_1=x$\n",
        "* $x_2=x^2$\n",
        "* $x_3=x^3$\n",
        "* $\\cdot$\n",
        "* $\\cdot$\n",
        "* $\\cdot$\n",
        "* $x_n=x^n$\n",
        "\n",
        "podemos tratar el problema como una regresión lineal múltiple de la forma\n",
        "\n",
        "\\begin{equation}\n",
        "\\hat{y}=w_0x_0+w_1x_1+w_2x_2\\cdots w_nx_x = \\sum_{i=0}^nw_ix_i\n",
        "\\end{equation}\n",
        "\n",
        "Por ende, la regresión polinómica se considera un caso especial de la regresión lineal múltiple, de tal forma que se pueden usar los mismos mecanismos que una regresión lineal para resolver el problema del modelado de los datos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xAd9QqNtQSJ"
      },
      "source": [
        "**Base de datos**\n",
        "\n",
        "A continuación, tomaremos un conjunto de datos correspondientes a la clasificaciones de consumo de combustibles específicas de los modelos de carros y las emisiones estimadas de dióxido de carbono de nuevos vehiculos ligeros para la venta al por menor en Canada. Para mayor información puede consultar el [link](http://open.canada.ca/data/en/dataset/98f1a129-f628-4ce4-b24d-6f16bf24dd64). La base de datos contienen características como:\n",
        "\n",
        "- **MODELYEAR** Año del vehiculo.\n",
        "- **MAKE** Marca o fabricante\n",
        "- **MODEL** Modelo del vehiculo.\n",
        "- **VEHICLE CLASS** Clase del vehiculo\n",
        "- **ENGINE SIZE** Tamaño del motor.\n",
        "- **CYLINDERS** Número de cilindros\n",
        "- **TRANSMISSION** Tipo de transmisión\n",
        "- **FUEL CONSUMPTION in CITY(L/100 km)** Consumo en ciudad en litros por cada 100 km.\n",
        "- **FUEL CONSUMPTION in HWY (L/100 km)** Consumo en autopista en litros por cada 100 km.\n",
        "- **FUEL CONSUMPTION COMB (L/100 km)** Consumo combinado en litros por cada 100 km.\n",
        "- **CO2 EMISSIONS (g/km)** Emisión en gramos por kilómetros."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "heooCccbtX37"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "#Lectura de los datos\n",
        "df = pd.read_csv(\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/ML0101ENv3/labs/FuelConsumptionCo2.csv\")\n",
        "\n",
        "# Inspección visual del dataset\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTDC1me4tm9M"
      },
      "source": [
        "Escojamos algunas características que estén relacionadas con la emisión de dioxido de carbono. Veamos la matriz de dispersión"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMjwfCImttR1"
      },
      "source": [
        "import seaborn as sns\n",
        "sns.set(style=\"ticks\")\n",
        "\n",
        "sns.pairplot(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJmZaLLWwFPu"
      },
      "source": [
        "Intentemos construir un modelo, mediante un ajuste polinomial, de la emisión de dióxido de carbono en función de la característica \"FUELCONSUMPTION_COMB_MPG\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgGob2LTwETj"
      },
      "source": [
        "# Escogemos nuestra variable predictora como Engine Size:\n",
        "X=df['FUELCONSUMPTION_COMB_MPG'].values.reshape(-1,1)\n",
        "\n",
        "# Escogemos nuestra variable objetivo como las emisiones de CO2:\n",
        "y=df['CO2EMISSIONS'].values.reshape(-1,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1SihdAbwUt-"
      },
      "source": [
        "**Train and test dataframe**\n",
        "\n",
        "Creemos ahora los grupos de train y test con los cuales entrenaremos y probaremos el modelo, respectivamente. Recordemos que este paso podemos hacerlo mediante la función `train_test_split` de la librería `sklearn.model_selection`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58yaYObIwUJF"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=20)\n",
        "\n",
        "print(x_train.shape,y_train.shape)\n",
        "print(x_test.shape,y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DguZO9h6wbNK"
      },
      "source": [
        "<h2 id=\"evaluation\">Regresión polinómica de los datos:</h2>\n",
        "\n",
        "Intentemos crear un modelo cuadrático de la emisión de dióxido de carbono en función del tamaño del motor:\n",
        "\n",
        "$\\hat{y} = w_o + w_1 x + w_2 x^2$\n",
        "\n",
        "En donde x reprenta la variable independiente 'FUELCONSUMPTION_COMB_MPG'. Para resolver este problema usamos la siguiente función:\n",
        "\n",
        "\n",
        "__PloynomialFeatures()__ es una función de la  librería Scikit-learn, la cual emplea nuevo conjunto de características del conjunto de características original. Es decir, se generará una matriz compuesta de todas las combinaciones polinomiales de las características de grado menor o igual especificado en `degree`. Por ejemplo, suponiendo que el conjunto inicial solo tienen una característica, _FUELCONSUMPTION_COMB_MPG_, entonces, si especificamos `degree=2`, se generarán tres caracteristicas dadas por `degree=0`, `degree=1` y `degree=2`: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBbjcIDCwan0"
      },
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "poly = PolynomialFeatures(degree=2)\n",
        "train_x_poly = poly.fit_transform(x_train)\n",
        "train_x_poly"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zDbowX5owpY2"
      },
      "source": [
        "El método **fit_transform** tomo los valores de x y crea una lista, elevando los valores en potencias enteras desde 0 hasta 2.\n",
        "\n",
        "$\n",
        "\\begin{bmatrix}\n",
        "    x_1\\\\\n",
        "    x_2\\\\\n",
        "    \\vdots\\\\\n",
        "    x_n\n",
        "\\end{bmatrix}\n",
        "$\n",
        "$\\longrightarrow$\n",
        "$\n",
        "\\begin{bmatrix}\n",
        "    [ 1 & x_1 & x_1^2]\\\\\n",
        "    [ 1 & x_2 & x_2^2]\\\\\n",
        "    \\vdots & \\vdots & \\vdots\\\\\n",
        "    [ 1 & x_n & x_n^2]\n",
        "\\end{bmatrix}\n",
        "$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJvjy6BEwu-y"
      },
      "source": [
        "De lo anterior se puede notar que se tiene la apariencia de un análisis de regresión multiple, lo que corrobora que la regresión polinómica representa un caso especial de la regresión lineal.\n",
        "\n",
        "A partir de este punto, podemos tratar nuestro problema como un caso de regresión lineal, de tal forma que podemos usar los mismos mecanismos que se emplean para resolver este tipo de problemas. Podemos usar, por ejemplo, la función  __LinearRegression()__ para solucionar nuestro problema:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZxbYz2MUwuO7"
      },
      "source": [
        "clf = LinearRegression()\n",
        "train_y_ = clf.fit(train_x_poly, y_train)\n",
        "# The coefficients\n",
        "print ('Coefficients: ', clf.coef_)\n",
        "print ('Intercept: ',clf.intercept_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1oGw1D2w-D8"
      },
      "source": [
        "En la celda anterior, __Coefficient__ e __Intercept__ corresponden a los parámetros del ajuste de la linea curva. \n",
        "\n",
        "Teniendo en cuenta que estamos tratando con una regresión lineal múltiple con 3 parámetros, los cuales representan la intersección y los coeficientes del hiperplano, sklearn los calcula a partir del nuevo conjunto de características. Veamos como luce el ajuste realizado sobre los datos de \"COEMISSION\" vs \"FUELCONSUMPTION_COMB_MPG\":"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjdpHpYDw9Wx"
      },
      "source": [
        "plt.scatter(X, y,  color='blue')\n",
        "XX = np.arange(0.0, 60.0, 0.1)\n",
        "yy = clf.intercept_[0]+ clf.coef_[0][1]*XX+ clf.coef_[0][2]*XX*XX\n",
        "plt.plot(XX, yy, '-r')\n",
        "plt.xlabel(\"FUELCONSUMPTION_COMB_MPG\")\n",
        "plt.ylabel(\"Emission\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aSw4ssPdxMVc"
      },
      "source": [
        "<h2 id=\"evaluation\">Evaluación</h2>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-wX8_yvvggD"
      },
      "source": [
        "#con la regresion lineal\n",
        "linear = LinearRegression()\n",
        "linear.fit(x_train,y_train)\n",
        "\n",
        "y_pred = linear.predict(x_test)\n",
        "\n",
        "print('MAE: %.3f '% metrics.mean_absolute_error(y_test, y_pred))\n",
        "print('MSE: %.3f'% metrics.mean_squared_error(y_test, y_pred))\n",
        "print('RMSE: %.3f'% np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
        "print('R2: %.3f'% metrics.r2_score(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zdruUC3ZxLlU"
      },
      "source": [
        "#con la regresion polinómica\n",
        "from sklearn import metrics\n",
        "test_x_poly = poly.fit_transform(x_test)\n",
        "test_y_ = clf.predict(test_x_poly)\n",
        "\n",
        "print('MAE: %.3f' % metrics.mean_absolute_error(test_y_, y_test))\n",
        "print('MSE: %.3f' % metrics.mean_squared_error(test_y_, y_test))\n",
        "print('RMSE: %.3f' % np.sqrt(metrics.mean_squared_error(test_y_, y_test)))\n",
        "print('R2: %.3f'% metrics.r2_score(test_y_, y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1YGQeoYbxSc3"
      },
      "source": [
        "# Problema:\n",
        "\n",
        "Relice un ajuste a un polinomio de grado tres en donde aplique cada uno de los pasos mostrados la regresión polinómica anterior, y evalue si obtiene un mejor modelo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W015zTKyxWX5"
      },
      "source": [
        "Hacer doble click <b>aquí</b> para ver la solución:\n",
        "\n",
        "<!-- Respuesta:\n",
        "\n",
        "# Código\n",
        "poly3 = PolynomialFeatures(degree=3)\n",
        "train_x_poly3 = poly3.fit_transform(x_train)\n",
        "\n",
        "clf3 = LinearRegression()\n",
        "train_y3_ = clf3.fit(train_x_poly3, y_train)\n",
        "\n",
        "#coeficientes\n",
        "print ('Coefficients: ', clf3.coef_)\n",
        "print ('Intercept: ',clf3.intercept_)\n",
        "\n",
        "#graficación\n",
        "plt.scatter(X, y, color=\"b\")\n",
        "XX = np.arange(0.0, 60.0, 0.1)\n",
        "Y = clf3.intercept_ + clf3.coef_[0][1]*XX + clf3.coef_[0][2]*XX**2 + clf3.coef_[0][3]*XX**3\n",
        "plt.plot(XX,Y,\"r-\" )\n",
        "plt.show()\n",
        "\n",
        "test_x_poly3 = poly3.fit_transform(x_test)\n",
        "test_y3_ = clf3.predict(test_x_poly3)\n",
        "\n",
        "print('MAE: %.3f ' % metrics.mean_absolute_error(y_test, test_y3_))\n",
        "print('MSE: %.3f' % metrics.mean_squared_error(y_test, test_y3_))\n",
        "print('RMSE: %.3f' % np.sqrt(metrics.mean_squared_error(y_test, test_y3_)))\n",
        "print('R2-score: %.3f'% metrics.r2_score(y_test, test_y3_))\n",
        "\n",
        "--->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nu6THzedvpW4"
      },
      "source": [
        "# Modelos no lineales\n",
        "\n",
        "Como bien sabemos, si los datos no presentan una tendencia lineal entre las características y las variables objetivo, debemos buscar ajustes a funciones no lineales para la construcción de modelos. Veamos algunas funciones de uso comun para el ajuste de modelos y un ejemplo práctico del crecimiento del producto interno bruto chino."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-dZEGHJvu1i"
      },
      "source": [
        "Las regresiones no lineales representan una relación entre variabres independientes $x$'s y una variable dependiente $y$, lo que resulta en un modelado mediante una función no lieal de los datos. En principio, cualquier relación que no es lineal, puede representarce mediante un polinomio de grado $k$. Por ejemplo: \n",
        "\n",
        "$$ \\ y = a x^3 + b x^2 + c x + d \\ $$\n",
        "\n",
        "Además, las funciones no lineales pueden tener elementos exponenciales, logarítmicos, fracciones, entre otros. Por \n",
        "ejemplo, una función de la forma:\n",
        "\n",
        "$$ y = \\log(a x^5 + b x^3 + c x + d)$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3aHR4KbWvzsU"
      },
      "source": [
        "## Función exponencial\n",
        "\n",
        "Una función exponencial de base c, se define como \n",
        "\n",
        "$Y = a + b c^X$\n",
        "\n",
        "en donde $b\\neq0$, $c > 0$ , $c\\neq1$, y la X es un número real. La base, $c$, es una constante y el exponente, $X$, es una variable. Un ejemplo gráfico de la función se presenta a continuación:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvVP-IqBv268"
      },
      "source": [
        "X = np.arange(-5.0, 5.0, 0.1)\n",
        "\n",
        "Y= np.exp(X)\n",
        "\n",
        "plt.plot(X,Y) \n",
        "plt.ylabel('Variable dependiente')\n",
        "plt.xlabel('Variable independiente')\n",
        "plt.title('Función exponencial')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kYDjYnYqwNNn"
      },
      "source": [
        "## Función logarítmica\n",
        "\n",
        "La función logarítmica es la función inversa de la función exponecial, y se representa como:\n",
        "\n",
        "\\begin{equation}\n",
        "y = \\log(X)\n",
        "\\end{equation}\n",
        "\n",
        "Una representación gráfica de esta función se muestra a continuación:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBw_a1GwwJug"
      },
      "source": [
        "X = np.arange(-5.0, 5.0, 0.1)\n",
        "\n",
        "Y = np.log(X)\n",
        "\n",
        "plt.plot(X,Y) \n",
        "plt.ylabel('Dependent Variable')\n",
        "plt.xlabel('Indepdendent Variable')\n",
        "plt.title('Función Logarítmica')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4qJeia9wWYh"
      },
      "source": [
        "## Función sigmoide/logística\n",
        "\n",
        "La función sigmoide tiene la forma \n",
        "\n",
        "$$ Y = a + \\frac{b}{1+ c^{(X-d)}}$$\n",
        "\n",
        "Y veremos, más adelante, en este curso, una aplicación en la la regresión logística. Una representación gráfica de la función se presenta a continuación:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hAiNgQCIwXwp"
      },
      "source": [
        "X = np.arange(-5.0, 5.0, 0.1)\n",
        "\n",
        "\n",
        "Y = 1-4/(1+np.power(3, X-2))\n",
        "\n",
        "plt.plot(X,Y) \n",
        "plt.ylabel('Dependent Variable')\n",
        "plt.xlabel('Indepdendent Variable')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HO5lMt14wdJj"
      },
      "source": [
        "## Ejemplo de regresión no lineal:\n",
        "\n",
        "Intentemos encontra un modelo no lineal para representar los datos del producto interno bruto de China, entre los años 1960 a 2014. El dataset se presenta a continuación:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ppICr_iOwhZb"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/ML0101ENv3/labs/china_gdp.csv\")\n",
        "df.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mD-rwyyzwmZa"
      },
      "source": [
        "### Gráfica del dataset ###\n",
        "\n",
        "Veamos como luce el dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Evp0GDPwlMr"
      },
      "source": [
        "plt.figure(figsize=(8,5))\n",
        "x_data, y_data = (df[\"Year\"].values, df[\"Value\"].values)\n",
        "plt.plot(x_data, y_data, 'ro')\n",
        "plt.ylabel('GDP')\n",
        "plt.xlabel('Year')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zoiBpCgHwyL1"
      },
      "source": [
        "Esta gráfica parece seguir un comportamiente logístico o exponencial. El crecimiento lento del PIB empieza alrededor del año 1995, y a partir del año 2005 empieza a ser significativo, para luego caer muy poco alrededor del 2010. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m8KFwFBcw8fK"
      },
      "source": [
        "### Determinación del modelo ###\n",
        "\n",
        "De una inspección inical, podemos determinar que una aproximación logística podría ser adecuada, ya que empieza a crecer lentamente, y aumenta a mitad de camino, para desacelerarse un poco al final. Veamos la siguiente función:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9e7zpDHw7W9"
      },
      "source": [
        "X = np.arange(-5.0, 5.0, 0.1)\n",
        "Y = 1.0 / (1.0 + np.exp(-X))\n",
        "\n",
        "plt.plot(X,Y) \n",
        "plt.ylabel('Dependent Variable')\n",
        "plt.xlabel('Indepdendent Variable')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wShg1xgZxB9S"
      },
      "source": [
        "De la ecuación de la función logística:\n",
        "\n",
        "$$ \\hat{Y} = \\frac1{1+e^{\\beta_1(X-\\beta_2)}}$$\n",
        "\n",
        "Tenemos que\n",
        "\n",
        "$\\beta_1$: contrala la inclinación de la curva,\n",
        "\n",
        "$\\beta_2$: proyecta la curva en x."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFYiPsW1xFnl"
      },
      "source": [
        "### Construcción del modelo###\n",
        "\n",
        "Construyamos nuestro modelo de regresión e inicialicemos los parámetros:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MsPvAo5LxJAL"
      },
      "source": [
        "def sigmoid(x, Beta_1, Beta_2):\n",
        "     y = 1 / (1 + np.exp(-Beta_1*(x-Beta_2)))\n",
        "     return y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qiphTYtLxQYj"
      },
      "source": [
        "Veamos un ajuste preliminar \"a  mano\" de una función sigmoide a los datos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mCYrTXNSxVxV"
      },
      "source": [
        "beta_1 = 0.10\n",
        "beta_2 = 2010.0\n",
        "\n",
        "#logistica\n",
        "Y_pred = sigmoid(x_data, beta_1 , beta_2)\n",
        "\n",
        "#plot predicción inicial\n",
        "plt.plot(x_data, Y_pred*15000000000000.)\n",
        "plt.plot(x_data, y_data, 'ro')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2316O339xamZ"
      },
      "source": [
        "El objetivo en este modelo es encontrar los parámetros que mejor ajustan la curva a los datos. Procedamos a normalizarlos:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUZqDr_4xejH"
      },
      "source": [
        "# normalicemos los datos\n",
        "xdata =x_data/max(x_data)\n",
        "ydata =y_data/max(y_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qah9E6YRxiPh"
      },
      "source": [
        "Usemos el método __curve_fit__ `scipy`, que usa un ajuste de mínimos cuadrados no lineal para ajustar nuesta función sigmoide a los datos. El algoritmo ajusta iterativamente los parámetros, de tal forma que la suma de los residuos cuadrados $sig(x_{data}, *popt) - y_{data}$ se minimiza."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71QWbpS2xnhb"
      },
      "source": [
        "from scipy.optimize import curve_fit\n",
        "popt, pcov = curve_fit(sigmoid, xdata, ydata)\n",
        "#imprimamos los parámetros\n",
        "print(\" beta_1 = %f, beta_2 = %f\" % (popt[0], popt[1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kum7lNGixrN4"
      },
      "source": [
        "# Visualización del modelo\n",
        "x = np.linspace(1960, 2015, 55)\n",
        "x = x/max(x)\n",
        "plt.figure(figsize=(8,5))\n",
        "y = sigmoid(x, *popt)\n",
        "plt.plot(xdata, ydata, 'ro', label='data')\n",
        "plt.plot(x,y, linewidth=3.0, label='fit')\n",
        "plt.legend(loc='best')\n",
        "plt.ylabel('GDP')\n",
        "plt.xlabel('Year')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKYbwe7QxvsD"
      },
      "source": [
        "## Problema:\n",
        "Evalue la precisión del modelo creado anteriormente."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_wv67D2fx32m"
      },
      "source": [
        "Hacer doble click <b>aquí</b> para ver la solución:\n",
        "\n",
        "<!-- Respuesta:\n",
        "\n",
        "#Reshape data\n",
        "X=xdata.reshape(-1,1)\n",
        "y=ydata.reshape(-1,1)\n",
        "\n",
        "#Split \n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(xdata,ydata, test_size=0.2, random_state=1)\n",
        "\n",
        "# crear el modelo\n",
        "popt, pcov = curve_fit(sigmoid, x_train, y_train)\n",
        "\n",
        "# predicciones sobre el dataset de test\n",
        "y_hat = sigmoid(x_test, *popt)\n",
        "\n",
        "# Evaluacion\n",
        "print(\"Mean absolute error: %.2f\" % np.mean(np.absolute(y_hat - y_test)))\n",
        "print(\"Residual sum of squares (MSE): %.2f\" % np.mean((y_hat - y_test) ** 2))\n",
        "from sklearn.metrics import r2_score\n",
        "print(\"R2-score: %.2f\" % r2_score(y_hat , y_test) )\n",
        "--->"
      ]
    }
  ]
}